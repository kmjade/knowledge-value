---
# 配置
tags: [ollama, installation]
---

# 配置

## 1. 下載 Ollama
- 前往官方網站 https://ollama.com 并下載对应平台的安裝包。
- 安裝完成後打開终端（Windows PowerShell、macOS Terminal、Linux Shell），運行 `ollama --version` 檢查是否成功安裝。

## 2. 新增模型仓库（可选）
```bash
# 新增模型仓库（示例）
ollama pull llama2
```
- 常用模型可以直接通過 `ollama pull <model>` 下載。
- 若想使用自定义模型，请參考官方文檔的 **自定义模型** 部分。

# 配置
- 默认情况下，Ollama 在本地 11434 端口提供 REST API。
# 修改
```bash
export OLLAMA_HOST=0.0.0.0
export OLLAMA_PORT=12345
ollama serve
```

## 4. 驗證安裝
# 顯示
```json
{"status":"ready"}
```

## 5. 与 Obsidian 整合
- 在 Obsidian 中安裝 **AI Assistant** 外掛（或其他支持 Ollama 的外掛）。
- 外掛設置中填寫 API 地址，例如 `http://localhost:11434/api/generate`，并選擇使用的模型（如 `llama2`）。

# 配置
