---
tags:
  - opencode
  - ollama
  - local-ai
  - prompt
  - request
created: <% tp.file.creation_date() %>
---

# ğŸ¦™ OpenCode + Ollama æœ¬åœ°è¯·æ±‚ / Local Request

## ğŸ“‹ ä¸Šä¸‹æ–‡è³‡è¨Š / Context Information

> [!info] å½“å‰æª”æ¡ˆ / Current File
> - **è·¯å¾‘**: `<% tp.file.path %>`
> - **æ ‡é¢˜**: `<% tp.file.title %>`
> - **å‰µå»ºæ™‚é–“**: `<% tp.file.creation_date() %>`

<%*
// è·å–æª”æ¡ˆä¸Šä¸‹æ–‡
const ctx = await tp.user.getOpenCodeContext(tp);
if (ctx) {
-%>

### ğŸ·ï¸ æ¨™ç±¤ / Tags
<% ctx.tags.map(t => `\`${t}\``).join(', ') %>

### ğŸ“ å‰ç½®å…ƒæ•¸æ“š / Frontmatter
```
<%*
    Object.entries(ctx.frontmatter).forEach(([key, value]) => {
        if (key !== 'tags') {
-%>
<% key %>: <% value %>
<%
        }
    });
-%>
```

### ğŸ“Š å…§å®¹çµ±è¨ˆ / Content Statistics
| æŒ‡æ ‡ / Metric | å€¼ / Value |
|---------------|-----------|
| **å­—ç¬¦æ•° / Characters** | `<% ctx.charCount %>` |
| **æ®µè½æ•° / Paragraphs** | `<% ctx.content.split('\n\n').length %>` |
| **é€£çµæ•° / Links** | `<% ctx.links.length %>` |
| **åˆ«åæ•° / Aliases** | `<% ctx.aliases.length %>` |

### ğŸ“„ æª”æ¡ˆé è¦½ / File Preview
<details>
# æŸ¥çœ‹

```text
# æŸ¥çœ‹
```
</details>

<%
} else {
-%>
> [!warning] ç„¡æ³•è·å–æª”æ¡ˆä¸Šä¸‹æ–‡ / Cannot get file context
> è¯·ç¡®ä¿åœ¨æœ‰æ•ˆæª”æ¡ˆä¸­é‹è¡Œæ­¤æ¨¡æ¿ / Please ensure running this template in a valid file
<%
}
-%>

---

## ğŸ¤– æ¨¡å‹é¸æ“‡ / Model Selection

<%*
// æª¢æŸ¥æœ¬åœ°æ¨¡å‹ç‹€æ…‹
const modelStatus = await tp.user.checkLocalModels();
const task = await tp.user.selectTaskType(tp);

if (modelStatus.status === 'unavailable') {
-%>

> [!danger] OllamaæœåŠ¡ä¸å¯ç”¨ / Ollama Service Unavailable
> 
> **é”™è¯¯è³‡è¨Š**: `<% modelStatus.error %>`
> 
# æ–¹æ³•
> 1. å•Ÿå‹•OllamaæœåŠ¡: `ollama serve`
> 2. æª¢æŸ¥ç«¯å£11434æ˜¯å¦è¢«å ç”¨
> 3. é©—è­‰Ollamaå®‰è£: `ollama --version`

<%
} else {
# é¡¯ç¤º
    const availableModels = modelStatus.models.map(m => m.name);
    const selectedModel = await tp.system.suggester(
        availableModels,
        availableModels,
        false,
        'é¸æ“‡æœ¬åœ°æ¨¡å‹ / Select local model:'
    );
    
    const recommendedModel = tp.user.recommendModel(task.type, task.requiresTools);
    const modelCapabilities = tp.user.getModelCapabilities(selectedModel);
-%>

### ğŸ¯ ä»»å‹™è³‡è¨Š / Task Information
| å°ˆæ¡ˆ / Item | å€¼ / Value |
|-----------|-----------|
| **ä»»å‹™ç±»å‹ / Task Type** | `<% task.name %>` |
| **éœ€è¦å·¥å…·ä½¿ç”¨ / Requires Tools** | `<% task.requiresTools ? 'æ˜¯ âœ…' : 'å¦ âŒ' %>` |
| **æ¨èæ¨¡å‹ / Recommended Model** | `<% recommendedModel %>` |
| **é¸æ“‡æ¨¡å‹ / Selected Model** | `<% selectedModel %>` |

### ğŸ” æ¨¡å‹èƒ½åŠ› / Model Capabilities
<%*
const capabilities = [
    { name: 'å·¥å…·èª¿ç”¨ / Tool Usage', value: modelCapabilities.tools },
    { name: 'ä¸Šä¸‹æ–‡è¦–çª— / Context Window', value: modelCapabilities.context + ' tokens' },
    { name: 'å“è³ªç­‰çº§ / Quality Level', value: modelCapabilities.quality }
];
-%>
<% capabilities.forEach(cap => { -%>
- **<% cap.name %>**: `<% cap.value ? 'âœ… ' + cap.value : 'âŒ ä¸æ”¯æŒ' %>`
<% }); -%>

<%*
if (task.requiresTools && !modelCapabilities.tools) {
-%>
> [!warning] âš ï¸ æ¨¡å‹ä¸æ”¯æŒå·¥å…·èª¿ç”¨ / Model Doesn't Support Tools
# ä¿®æ”¹
> - **qwen2.5-coder:7b** - æ¨èé¸æ“‡
> - **qwen2.5-coder:14b** - é«˜æ•ˆèƒ½é¸æ“‡
> - **deepseek-coder:6.7b** - å¤‡é€‰æ–¹æ¡ˆ

<%
}
-%>

---
## ğŸ’¬ æŒ‡ä»¤è¼¸å…¥ / Instructions

<%*
// ä½¿ç”¨è€…æŒ‡ä»¤è¼¸å…¥
const userPrompt = await tp.system.prompt(
    "è¯·è¼¸å…¥å…·ä½“æŒ‡ä»¤ï¼ˆæ”¯æŒä¸­æ–‡/è‹±æ–‡ï¼‰ / Enter your instructions (Chinese/English supported):",
# åˆ†æ
    true
);

const command = tp.user.generateOpenCodeCommand(userPrompt, selectedModel, {
    noThink: task.type === 'generation' || task.type === 'refactoring',
    timeout: modelCapabilities.context > 16000 ? 300 : 120
});
-%>

### ğŸ“ æ‚¨çš„æŒ‡ä»¤ / Your Instructions
```text
<% userPrompt %>
```

### ğŸš€ OpenCode å‘½ä»¤ / OpenCode Command
<details>
<summary>ç‚¹å‡»è¤‡è£½å‘½ä»¤ / Click to copy command</summary>

```bash
<% command %>
```

**å‘½ä»¤è§£æ / Command Analysis**:
<%*
const commandParts = [
    { name: 'åŸºç¤å‘½ä»¤', value: 'opencode run' },
    { name: 'ä»»å‹™æè¿°', value: `"${userPrompt}"` },
    { name: 'æ¨¡å‹é¸æ“‡', value: `--model ollama/${selectedModel}` }
];

if (task.type === 'generation') {
    commandParts.push({ name: 'æ€è€ƒæ¨¡å¼', value: '--no-think' });
}

if (modelCapabilities.context > 16000) {
    commandParts.push({ name: 'è¶…æ—¶æ™‚é–“', value: '--timeout 300' });
}
-%>
<% commandParts.forEach(part => { -%>
- **<% part.name %>**: `<% part.value %>`
<% }); -%>
</details>

---

## âš¡ æ•ˆèƒ½é¢„æœŸ / Performance Expectations

<%*
// æ ¹æ®æ¨¡å‹å’Œä»»å‹™ä¼°ç®—æ•ˆèƒ½
const performanceMap = {
    'qwen2.5-coder:14b': { min: '8-15', avg: '12', max: '20' },
    'qwen2.5-coder:7b': { min: '15-25', avg: '20', max: '35' },
    'qwen2.5:7b': { min: '20-35', avg: '28', max: '45' },
    'qwen2.5:3b': { min: '30-60', avg: '45', max: '80' },
    'mistral-nemo:12b': { min: '15-30', avg: '22', max: '40' }
};

const perf = performanceMap[selectedModel] || { min: '10-20', avg: '15', max: '30' };
const estimatedTime = task.requiresTools ? (parseInt(perf.avg) * 1.5) : perf.avg;
-%>

| æ¨¡å‹ / Model | é¢„æœŸæ™‚é–“ / Expected Time | å“è³ª / Quality | é€‚ç”¨å ´æ™¯ / Use Case |
|---------------|------------------------|---------------|-------------------|
# åˆ†æ

> [!tip] ğŸ’¡ æ•ˆèƒ½æç¤º / Performance Tips
> - **é¦–æ¬¡é‹è¡Œ**å¯èƒ½è¾ƒæ…¢ï¼ˆæ¨¡å‹åŠ è½½æ™‚é–“ï¼‰
> - **å¤§ä¸Šä¸‹æ–‡**ä»»å‹™éœ€è¦æ›´å¤šæ™‚é–“
> - **å·¥å…·èª¿ç”¨**ä¼šé¢å¤–å¢åŠ è™•ç†æ™‚é–“
> - **GPUä½¿ç”¨**ä¼šæ˜¾è‘—æå‡é€Ÿåº¦

---

## ğŸ“¤ æ‰§è¡Œæ­¥éª¤ / Execution Steps

> [!important] æœ¬åœ°æ‰§è¡Œæ­¥éª¤ / Local Execution Steps
> 
> ### ğŸ”§ å‡†å¤‡æª¢æŸ¥ / Preparation Check
> - [ ] **OllamaæœåŠ¡é‹è¡Œ**: `ollama serve`
> - [ ] **æ¨¡å‹å¯ç”¨**: `ollama list | grep <% selectedModel.split(':')[0] %>`
> - [ ] **ç«¯å£å¯ç”¨**: `curl -s http://localhost:11434/api/tags`
> - [ ] **è¨˜æ†¶é«”å……è¶³**: `free -h` æˆ–æª¢æŸ¥æ´»åŠ¨ç›‘è§†å™¨
> 
> ### ğŸš€ æ‰§è¡Œå‘½ä»¤ / Execute Command
> 1. è¤‡è£½ä¸Šé¢ç”Ÿæˆçš„å‘½ä»¤ / Copy the command above
> 2. åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œ / Run in terminal
> 3. ç­‰å¾…è™•ç†å®Œæˆ / Wait for completion
> 4. è§‚å¯Ÿè¼¸å‡ºçµæœ / Monitor output
> 
> ### ğŸ“‹ çµæœè¨˜éŒ„ / Record Results
> - [ ] æˆåŠŸå®Œæˆ / Successfully completed
> - [ ] éƒ¨åˆ†æˆåŠŸ / Partially successful  
> - [ ] éœ€è¦é‡è¯• / Need to retry

---

## ğŸ“Š è¼¸å‡ºçµæœ / Output Results

> [!note] ğŸ“¤ çµæœè²¼ä¸ŠåŒº / Result Paste Area
> åœ¨æ­¤è²¼ä¸ŠOpenCodeçš„è¿”å›çµæœ / Paste OpenCode response here

<details>
<summary>çµæœæ¨¡æ¿ / Result Template</summary>

### âœ… æ‰§è¡Œç‹€æ…‹ / Execution Status
- **é–‹å§‹æ™‚é–“**: 
- **çµæŸæ™‚é–“**: 
- **æ€»è€—æ—¶**: 
- **æˆåŠŸåº¦**: 

### ğŸ“ AIè¼¸å‡º / AI Output
```
[åœ¨æ­¤è²¼ä¸ŠOpenCodeçš„è¿”å›çµæœ / Paste OpenCode response here]
```

# åˆ†æ
- **è¼¸å‡ºå“è³ª**: 
- **æ˜¯å¦æ»¡è¶³éœ€æ±‚**: 
- **éœ€è¦æ”¹è¿›çš„åœ°æ–¹**: 

### ğŸ”„ å¾ŒçºŒè¡ŒåŠ¨ / Next Actions
# ä¿®æ”¹
- [ ] ç”Ÿæˆç›¸é—œæ–‡æª”
- [ ] é€²è¡Œæ¸¬è©¦é©—è­‰
- [ ] æ•´åˆåˆ°å°ˆæ¡ˆä¸­

</details>

---

## ğŸ”§ æ•…éšœæ’é™¤ / Troubleshooting

<details>
<summary>å¸¸è§å•é¡ŒåŠè§£æ±ºæ–¹æ¡ˆ / Common Issues & Solutions</summary>

### âŒ å•é¡Œ1: æ¨¡å‹æœªæ‰¾åˆ°
**ç—‡çŠ¶**: `Error: model not found`
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥å¯ç”¨æ¨¡å‹
ollama list

# ä¸‹è¼‰ç¼ºå¤±æ¨¡å‹
ollama pull <% selectedModel %>

# é©—è­‰ä¸‹è¼‰
ollama show <% selectedModel %>
```

### âŒ å•é¡Œ2: é€£æ¥Ollamaå¤±è´¥
**ç—‡çŠ¶**: `Error: connection refused`
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# é‡å¯OllamaæœåŠ¡
pkill ollama && ollama serve &

# æª¢æŸ¥ç«¯å£å ç”¨
netstat -an | grep 11434

# æ¸¬è©¦é€£æ¥
curl http://localhost:11434/api/tags
```

### âŒ å•é¡Œ3: è¨˜æ†¶é«”ä¸è¶³
**ç—‡çŠ¶**: `Error: out of memory` æˆ–ç³»çµ±å¡é¡¿
**è§£æ±ºæ–¹æ¡ˆ**:
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚qwen2.5:3bï¼‰
- å‡å°‘å¹¶å‘ä»»å‹™
- é—œé–‰å…¶ä»–å ç”¨è¨˜æ†¶é«”çš„ç¨‹å¼
- é‡å¯ç³»çµ±æ¸…ç†è¨˜æ†¶é«”

### âŒ å•é¡Œ4: éŸ¿æ‡‰è¿‡æ…¢
**ç—‡çŠ¶**: è™•ç†æ™‚é–“è¿‡é•¿ï¼ˆ>5åˆ†é’Ÿï¼‰
**è§£æ±ºæ–¹æ¡ˆ**:
- æª¢æŸ¥GPUæ˜¯å¦è¢«ä½¿ç”¨ï¼š`nvidia-smi`
- ä½¿ç”¨é‡åŒ–æ¨¡å‹
- å‡å°‘ä¸Šä¸‹æ–‡è¦–çª—å¤§å°
- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹

</details>

---

## ğŸ”— ç›¸é—œè³‡æº / Related Resources

### ğŸ“– æ–‡æª”é€£çµ / Documentation Links
# æŒ‡å—
- **[Ollamaæ¨¡å‹åº“](https://ollama.ai/library)** - å¯ç”¨æ¨¡å‹åˆ—è¡¨
# æŒ‡å—

### ğŸ› ï¸ å¿«é€Ÿå‘½ä»¤ / Quick Commands
```bash
# æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
ollama list

# æŸ¥çœ‹
ollama show <% selectedModel %>

# æ¸¬è©¦OpenCodeé€£æ¥
opencode --version

# æŸ¥çœ‹
opencode models
```

### ğŸ“š å­¸ç¿’è³‡æº / Learning Resources
# æ•™ç¨‹
- **[æ¨¡å‹æ•ˆèƒ½å°æ¯”](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)** - æ¨¡å‹æ’è¡Œæ¦œ
- **[OpenCodeç¤¾å€](https://opencode.ai/discord)** - ä½¿ç”¨è€…äº¤æµç¤¾å€

---

# æ›´æ–°

# æ›´æ–°
|---------------|-------------|-------------------|
# ç‰ˆæœ¬

---

> [!success] ğŸ‰ æ¨¡æ¿ä½¿ç”¨æˆåŠŸ / Template Used Successfully
> æ‚¨å·²æˆåŠŸå‰µå»ºOpenCodeæœ¬åœ°è¯·æ±‚æ–‡æª”ï¼ç°åœ¨å¯ä»¥ï¼š
> 1. è¤‡è£½ä¸Šé¢çš„OpenCodeå‘½ä»¤
> 2. åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œ
> 3. å°†çµæœè²¼ä¸Šåˆ°"è¼¸å‡ºçµæœ"åŒºåŸŸ
> 4. æ ¹æ®çµæœé€²è¡Œå¾ŒçºŒæ“ä½œ

*æ­¤æ¨¡æ¿åŸºäºOpenCode + Ollamaæœ€ä½³å¯¦è¸é–‹ç™¼ / This template is based on OpenCode + Ollama best practices*