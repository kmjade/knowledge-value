# ğŸ”§ æ•…éšœæ’é™¤èˆ‡ç¶­è­·æŒ‡å—

> ğŸ¯ **ç« ç¯€ç›®æ¨™**ï¼šè§£æ±ºé›†æˆå•é¡Œä¸¦é€²è¡Œç³»çµ±ç¶­è­· | â±ï¸ **é è¨ˆæ™‚é–“**ï¼š45åˆ†é˜ | ğŸ“Š **é›£åº¦ç­‰ç´š**ï¼šâ­â­

## ğŸ“– æ¦‚è¿°

æœ¬æŒ‡å—å°‡è©³ç´°ä»‹ç´¹Obsidian+OpenCode+Ollama+GPT-oss:120b-cloudé›†æˆç³»çµ±çš„å¸¸è¦‹æ•…éšœè§£æ±ºæ–¹æ¡ˆå’Œç¶­è­·ç­–ç•¥ï¼Œå¹«åŠ©æ‚¨ä¿æŒç³»çµ±ç©©å®šé‹è¡Œã€‚

## ğŸš¨ å¸¸è¦‹å•é¡Œåˆ†é¡

### ğŸ“‹ å•é¡Œé¡å‹çµ±è¨ˆ
```mermaid
pie title å•é¡Œé¡å‹åˆ†ä½ˆ
    "é€£æ¥å•é¡Œ" : 35
    "æ€§èƒ½å•é¡Œ" : 25
    "é…ç½®å•é¡Œ" : 20
    "å…¼å®¹æ€§å•é¡Œ" : 15
    "å…¶ä»–å•é¡Œ" : 5
```

## ğŸ”Œ é€£æ¥å•é¡Œ

### Obsidiané€£æ¥å•é¡Œ

#### å•é¡Œ1ï¼šAIæ’ä»¶ç„¡æ³•é€£æ¥
```yaml
å•é¡Œæè¿°:
  ç—‡ç‹€: Text Generatoræ’ä»¶é¡¯ç¤º"é€£æ¥å¤±æ•—"
  å½±éŸ¿ç¯„åœ: ç„¡æ³•ä½¿ç”¨AIåŠŸèƒ½
  
è¨ºæ–·æ­¥é©Ÿ:
  - æª¢æŸ¥APIå¯†é‘°æ˜¯å¦æ­£ç¢º
  - æª¢æŸ¥ç¶²çµ¡é€£æ¥æ˜¯å¦æ­£å¸¸
  - æª¢æŸ¥APIæœå‹™æ˜¯å¦å¯ç”¨
  - æª¢æŸ¥æ’ä»¶ç‰ˆæœ¬æ˜¯å¦éèˆŠ

è§£æ±ºæ–¹æ¡ˆ:
  immediate_action: "æª¢æŸ¥APIå¯†é‘°é…ç½®"
  secondary_action: "æ¸¬è©¦ç¶²çµ¡é€£æ¥"
  tertiary_action: "æ›´æ–°æ’ä»¶ç‰ˆæœ¬"
```

#### å•é¡Œ2ï¼šé›²ç«¯APIè¶…æ™‚
```python
# è¨ºæ–·è…³æœ¬
import requests
import time

def diagnose_api_timeout(api_base, api_key):
    """è¨ºæ–·APIè¶…æ™‚å•é¡Œ"""
    print("é–‹å§‹APIè¶…æ™‚è¨ºæ–·...")
    
    # 1. æª¢æŸ¥åŸºç¤é€£æ¥
    print("1. æª¢æŸ¥åŸºç¤é€£æ¥...")
    try:
        start_time = time.time()
        response = requests.get(f"{api_base}/models", 
                             headers={"Authorization": f"Bearer {api_key}"},
                             timeout=5)
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            print(f"   âœ… åŸºç¤é€£æ¥æ­£å¸¸ï¼ˆ{elapsed:.2f}ç§’ï¼‰")
        else:
            print(f"   âš ï¸  APIéŸ¿æ‡‰ç•°å¸¸ï¼š{response.status_code}")
    except requests.exceptions.Timeout:
        print("   âŒ é€£æ¥è¶…æ™‚")
    except Exception as e:
        print(f"   âŒ é€£æ¥éŒ¯èª¤ï¼š{e}")
    
    # 2. æ¸¬è©¦æ¨¡å‹èª¿ç”¨
    print("2. æ¸¬è©¦æ¨¡å‹èª¿ç”¨...")
    try:
        start_time = time.time()
        response = requests.post(
            f"{api_base}/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": "gpt-oss:120b-cloud",
                "messages": [{"role": "user", "content": "æ¸¬è©¦"}],
                "max_tokens": 50
            },
            timeout=10
        )
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            print(f"   âœ… æ¨¡å‹èª¿ç”¨æˆåŠŸï¼ˆ{elapsed:.2f}ç§’ï¼‰")
            return True
        else:
            print(f"   âš ï¸  APIéŒ¯èª¤ï¼š{response.status_code}")
            return False
    except requests.exceptions.Timeout:
        print("   âŒ  æ¨¡å‹èª¿ç”¨è¶…æ™‚")
        return False
    except Exception as e:
        print(f"   âŒ  èª¿ç”¨éŒ¯èª¤ï¼š{e}")
        return False

# ä½¿ç”¨ç¤ºä¾‹
diagnose_api_timeout(
    api_base="https://api.gpt-oss.com/v1",
    api_key="your-api-key-here"
)
```

### Ollamaé€£æ¥å•é¡Œ

#### å•é¡Œ3ï¼šOllamaæœå‹™ç„¡æ³•å•Ÿå‹•
```bash
# Ollamaæœå‹™è¨ºæ–·è…³æœ¬
#!/bin/bash

echo "ğŸ” Ollamaæœå‹™è¨ºæ–·é–‹å§‹..."

# 1. æª¢æŸ¥é€²ç¨‹
echo "1. æª¢æŸ¥Ollamaé€²ç¨‹..."
if pgrep -x "ollama" > /dev/null; then
    echo "   âœ… Ollamaé€²ç¨‹æ­£åœ¨é‹è¡Œ"
    PID=$(pgrep -x "ollama")
    echo "   é€²ç¨‹ID: $PID"
else
    echo "   âŒ Ollamaé€²ç¨‹æœªé‹è¡Œ"
    echo "   å˜—è©¦å•Ÿå‹•Ollamaæœå‹™..."
    ollama serve &
    sleep 5
fi

# 2. æª¢æŸ¥ç«¯å£ä½”ç”¨
echo "2. æª¢æŸ¥11434ç«¯å£..."
if netstat -tuln 2>/dev/null | grep -q ":11434 "; then
    echo "   âœ… ç«¯å£11434å·²é–‹æ”¾"
else
    echo "   âŒ ç«¯å£11434æœªé–‹æ”¾"
    echo "   å˜—è©¦å•Ÿå‹•Ollamaæœå‹™..."
    ollama serve &
    sleep 10
fi

# 3. æ¸¬è©¦APIé€£æ¥
echo "3. æ¸¬è©¦APIé€£æ¥..."
if curl -s http://localhost:11434/api/version > /dev/null; then
    echo "   âœ… APIé€£æ¥æ­£å¸¸"
    curl -s http://localhost:11434/api/version
else
    echo "   âŒ APIé€£æ¥å¤±æ•—"
fi

# 4. æª¢æŸ¥å·²ä¸‹è¼‰æ¨¡å‹
echo "4. æª¢æŸ¥å·²ä¸‹è¼‰æ¨¡å‹..."
ollama list

# 5. æª¢æŸ¥ç£ç¢Ÿç©ºé–“
echo "5. æª¢æŸ¥ç£ç¢Ÿç©ºé–“..."
df -h ~/.ollama | tail -1

echo "ğŸ” è¨ºæ–·å®Œæˆ"
```

#### å•é¡Œ4ï¼šæ¨¡å‹ä¸‹è¼‰å¤±æ•—
```python
# æ¨¡å‹ä¸‹è¼‰è¨ºæ–·è…³æœ¬
import requests
import subprocess
import os

class OllamaModelDownloader:
    def __init__(self):
        self.ollama_host = "localhost:11434"
    
    def check_connection(self):
        """æª¢æŸ¥Ollamaé€£æ¥"""
        try:
            response = requests.get(f"http://{self.ollama_host}/api/version")
            if response.status_code == 200:
                print("âœ… Ollamaæœå‹™é€£æ¥æ­£å¸¸")
                return True
            else:
                print(f"âš ï¸  Ollamaæœå‹™ç•°å¸¸ï¼š{response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ é€£æ¥å¤±æ•—ï¼š{e}")
            return False
    
    def check_disk_space(self):
        """æª¢æŸ¥ç£ç¢Ÿç©ºé–“"""
        try:
            import shutil
            total, used, free = shutil.disk_usage("/")
            
            free_gb = free / (1024**3)
            
            if free_gb < 10:
                print(f"âš ï¸  ç£ç¢Ÿç©ºé–“ä¸è¶³ï¼šå‰©é¤˜{free_gb:.1f}GB")
                return False
            else:
                print(f"âœ… ç£ç¢Ÿç©ºé–“å……è¶³ï¼šå‰©é¤˜{free_gb:.1f}GB")
                return True
        except Exception as e:
            print(f"âŒ  ç£ç¢Ÿæª¢æŸ¥å¤±æ•—ï¼š{e}")
            return False
    
    def download_model(self, model_name):
        """ä¸‹è¼‰æ¨¡å‹"""
        if not self.check_connection():
            print("è«‹å…ˆå•Ÿå‹•Ollamaæœå‹™")
            return False
        
        if not self.check_disk_space():
            print("è«‹é‡‹æ”¾ç£ç¢Ÿç©ºé–“")
            return False
        
        print(f"é–‹å§‹ä¸‹è¼‰æ¨¡å‹ï¼š{model_name}")
        
        try:
            result = subprocess.run(
                ["ollama", "pull", model_name],
                capture_output=True,
                text=True,
                timeout=1800  # 30åˆ†é˜è¶…æ™‚
            )
            
            if result.returncode == 0:
                print(f"âœ… æ¨¡å‹ä¸‹è¼‰æˆåŠŸï¼š{model_name}")
                return True
            else:
                print(f"âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼š{result.stderr}")
                return False
        except subprocess.TimeoutExpired:
            print("âŒ ä¸‹è¼‰è¶…æ™‚")
            return False
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—ï¼š{e}")
            return False
    
    def list_models(self):
        """åˆ—å‡ºå·²ä¸‹è¼‰æ¨¡å‹"""
        try:
            result = subprocess.run(
                ["ollama", "list"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                print("å·²ä¸‹è¼‰æ¨¡å‹ï¼š")
                print(result.stdout)
            else:
                print(f"åˆ—å‡ºæ¨¡å‹å¤±æ•—ï¼š{result.stderr}")
        except Exception as e:
            print(f"éŒ¯èª¤ï¼š{e}")

# ä½¿ç”¨ç¤ºä¾‹
downloader = OllamaModelDownloader()

# è¨ºæ–·Ollamaæœå‹™
downloader.check_connection()

# ä¸‹è¼‰æ¨¡å‹
downloader.download_model("llama2:7b")

# åˆ—å‡ºæ¨¡å‹
downloader.list_models()
```

## âš¡ æ€§èƒ½å•é¡Œ

### OpenCodeæ€§èƒ½å„ªåŒ–

#### å•é¡Œ5ï¼šä»£ç¢¼ç”Ÿæˆé€Ÿåº¦æ…¢
```python
# æ€§èƒ½å„ªåŒ–è…³æœ¬
import time
import psutil
from typing import Dict, Any

class PerformanceOptimizer:
    def __init__(self):
        self.metrics = []
    
    def analyze_performance(self) -> Dict[str, Any]:
        """åˆ†æç³»çµ±æ€§èƒ½"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        performance = {
            "cpu": {
                "usage": cpu_percent,
                "load": psutil.getloadavg()
            },
            "memory": {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent
            },
            "disk": {
                "total": disk.total,
                "used": disk.used,
                "free": disk.free,
                "percent": disk.percent
            }
        }
        
        self._generate_recommendations(performance)
        return performance
    
    def _generate_recommendations(self, performance: Dict[str, Any]):
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []
        
        # CPUå„ªåŒ–å»ºè­°
        if performance["cpu"]["usage"] > 80:
            recommendations.append({
                "type": "cpu",
                "severity": "high",
                "message": "CPUä½¿ç”¨ç‡éé«˜",
                "actions": [
                    "æ¸›å°‘ä¸¦ç™¼ä»»å‹™æ•¸é‡",
                    "ä½¿ç”¨æ›´é«˜æ•ˆçš„æ¨¡å‹",
                    "å„ªåŒ–ç®—æ³•è¤‡é›œåº¦"
                ]
            })
        
        # å…§å­˜å„ªåŒ–å»ºè­°
        if performance["memory"]["percent"] > 80:
            recommendations.append({
                "type": "memory",
                "severity": "high",
                "message": "å…§å­˜ä½¿ç”¨ç‡éé«˜",
                "actions": [
                    "ä½¿ç”¨æ›´å°çš„æ¨¡å‹",
                    "æ¸›å°‘ä¸Šä¸‹æ–‡é•·åº¦",
                    "æ¸…ç†æœªä½¿ç”¨çš„æ¨¡å‹",
                    "å¢åŠ äº¤æ›ç©ºé–“"
                ]
            })
        
        # ç£ç¢Ÿå„ªåŒ–å»ºè­°
        if performance["disk"]["percent"] > 80:
            recommendations.append({
                "type": "disk",
                "severity": "medium",
                "message": "ç£ç¢Ÿç©ºé–“ä¸è¶³",
                "actions": [
                    "æ¸…ç†ç·©å­˜æ–‡ä»¶",
                    "åˆªé™¤ä¸éœ€è¦çš„æ¨¡å‹",
                    "å¢åŠ å­˜å„²ç©ºé–“"
                ]
            })
        
        if recommendations:
            print("âš ï¸  æ€§èƒ½å„ªåŒ–å»ºè­°ï¼š")
            for i, rec in enumerate(recommendations, 1):
                print(f"{i}. {rec['message']}")
                for action in rec['actions']:
                    print(f"   - {action}")
        else:
            print("âœ… ç³»çµ±æ€§èƒ½è‰¯å¥½ï¼Œç„¡éœ€å„ªåŒ–")

# ä½¿ç”¨ç¤ºä¾‹
optimizer = PerformanceOptimizer()
performance = optimizer.analyze_performance()
```

### APIèª¿ç”¨å„ªåŒ–

#### å•é¡Œ6ï¼šAPIèª¿ç”¨é »ç‡é™åˆ¶
```python
# APIèª¿ç”¨å„ªåŒ–ç®¡ç†å™¨
import time
import requests
from datetime import datetime, timedelta
from collections import defaultdict, deque
from threading import Lock

class RateLimitManager:
    def __init__(self, max_requests_per_minute=60):
        self.max_requests = max_requests_per_minute
        self.request_times = defaultdict(deque)
        self.lock = Lock()
    
    def make_request(self, api_url, api_key, payload):
        """å¸¶é€Ÿç‡é™åˆ¶çš„APIè«‹æ±‚"""
        with self.lock:
            # æ¸…ç†èˆŠè«‹æ±‚è¨˜éŒ„
            self._cleanup_old_requests(api_key)
            
            # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
            if len(self.request_times[api_key]) >= self.max_requests:
                # ç­‰å¾…åˆ°æœ€èˆŠè«‹æ±‚è¶…é1åˆ†é˜
                oldest_request = self.request_times[api_key][0]
                wait_time = (oldest_request + timedelta(minutes=1)) - datetime.now()
                
                if wait_time.total_seconds() > 0:
                    print(f"é”åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…{wait_time.total_seconds():.1f}ç§’...")
                    time.sleep(wait_time.total_seconds() + 1)
            
            # è¨˜éŒ„è«‹æ±‚æ™‚é–“
            self.request_times[api_key].append(datetime.now())
        
        # ç™¼é€è«‹æ±‚
        try:
            response = requests.post(
                api_url,
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json=payload,
                timeout=30
            )
            
            return response
        except Exception as e:
            print(f"è«‹æ±‚å¤±æ•—ï¼š{e}")
            raise
    
    def _cleanup_old_requests(self, api_key):
        """æ¸…ç†èˆŠè«‹æ±‚è¨˜éŒ„"""
        if api_key in self.request_times:
            cutoff_time = datetime.now() - timedelta(minutes=1)
            while self.request_times[api_key] and \
                  self.request_times[api_key][0] < cutoff_time:
                self.request_times[api_key].popleft()
    
    def get_remaining_requests(self, api_key):
        """ç²å–å‰©é¤˜è«‹æ±‚æ¬¡æ•¸"""
        with self.lock:
            self._cleanup_old_requests(api_key)
            return self.max_requests - len(self.request_times.get(api_key, []))

# ä½¿ç”¨ç¤ºä¾‹
rate_limiter = RateLimitManager(max_requests_per_minute=60)

# æª¢æŸ¥å‰©é¤˜è«‹æ±‚æ¬¡æ•¸
remaining = rate_limiter.get_remaining_requests("your-api-key")
print(f"å‰©é¤˜è«‹æ±‚æ¬¡æ•¸ï¼š{remaining}")

# åŸ·è¡Œè«‹æ±‚ï¼ˆè‡ªå‹•è™•ç†é€Ÿç‡é™åˆ¶ï¼‰
response = rate_limiter.make_request(
    api_url="https://api.gpt-oss.com/v1/chat/completions",
    api_key="your-api-key",
    payload={
        "model": "gpt-oss:120b-cloud",
        "messages": [{"role": "user", "content": "æ¸¬è©¦"}],
        "max_tokens": 50
    }
)
```

## ğŸ“‹ é…ç½®å•é¡Œ

### é…ç½®æ–‡ä»¶å•é¡Œ

#### å•é¡Œ7ï¼šé…ç½®æ–‡ä»¶èªæ³•éŒ¯èª¤
```yaml
# é…ç½®æ–‡ä»¶é©—è­‰è…³æœ¬
import yaml
import json
from pathlib import Path
from typing import Dict, Any

class ConfigValidator:
    def __init__(self):
        self.schema = self._load_schema()
    
    def _load_schema(self) -> Dict[str, Any]:
        """åŠ è¼‰é…ç½®æ¶æ§‹"""
        return {
            "version": {"type": str, "required": True},
            "api": {
                "type": dict,
                "required": True,
                "properties": {
                    "base_url": {"type": str, "required": True},
                    "api_key": {"type": str, "required": True},
                    "model": {"type": str, "required": True}
                }
            },
            "models": {
                "type": dict,
                "required": True,
                "properties": {
                    "primary": {"type": str, "required": True},
                    "fallback": {"type": str, "required": True}
                }
            }
        }
    
    def validate_config(self, config_path: str) -> Dict[str, Any]:
        """é©—è­‰é…ç½®æ–‡ä»¶"""
        print(f"é©—è­‰é…ç½®æ–‡ä»¶ï¼š{config_path}")
        
        # 1. æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(config_path).exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{config_path}")
            return {"valid": False, "errors": ["æ–‡ä»¶ä¸å­˜åœ¨"]}
        
        # 2. è®€å–é…ç½®æ–‡ä»¶
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
        except yaml.YAMLError as e:
            print(f"âŒ YAMLèªæ³•éŒ¯èª¤ï¼š{e}")
            return {"valid": False, "errors": [f"YAMLèªæ³•éŒ¯èª¤ï¼š{e}"]}
        except Exception as e:
            print(f"âŒ è®€å–é…ç½®æ–‡ä»¶å¤±æ•—ï¼š{e}")
            return {"valid": False, "errors": [f"è®€å–éŒ¯èª¤ï¼š{e}"]}
        
        # 3. é©—è­‰å¿…å¡«å­—æ®µ
        errors = []
        warnings = []
        
        # é©—è­‰ç‰ˆæœ¬
        if "version" not in config:
            errors.append("ç¼ºå°‘å¿…å¡«å­—æ®µï¼šversion")
        elif not isinstance(config["version"], str):
            errors.append("versionå­—æ®µé¡å‹éŒ¯èª¤ï¼Œæ‡‰ç‚ºå­—ç¬¦ä¸²")
        
        # é©—è­‰APIé…ç½®
        if "api" not in config:
            errors.append("ç¼ºå°‘å¿…å¡«å­—æ®µï¼šapi")
        else:
            api_config = config["api"]
            required_api_fields = ["base_url", "api_key", "model"]
            for field in required_api_fields:
                if field not in api_config:
                    errors.append(f"ç¼ºå°‘å¿…å¡«å­—æ®µï¼šapi.{field}")
        
        # é©—è­‰æ¨¡å‹é…ç½®
        if "models" not in config:
            errors.append("ç¼ºå°‘å¿…å¡«å­—æ®µï¼šmodels")
        else:
            models_config = config["models"]
            required_model_fields = ["primary", "fallback"]
            for field in required_model_fields:
                if field not in models_config:
                    errors.append(f"ç¼ºå°‘å¿…å¡«å­—æ®µï¼šmodels.{field}")
            
            # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            primary_model = models_config.get("primary", "")
            if primary_model:
                self._check_model_exists(primary_model)
        
        # ç”Ÿæˆé©—è­‰çµæœ
        if errors:
            print("âŒ é…ç½®é©—è­‰å¤±æ•—")
            for error in errors:
                print(f"   - {error}")
            return {"valid": False, "errors": errors, "warnings": warnings}
        elif warnings:
            print("âš ï¸  é…ç½®é©—è­‰é€šéï¼Œä½†æœ‰è­¦å‘Š")
            for warning in warnings:
                print(f"   - {warning}")
            return {"valid": True, "errors": [], "warnings": warnings}
        else:
            print("âœ… é…ç½®é©—è­‰é€šé")
            return {"valid": True, "errors": [], "warnings": []}
    
    def _check_model_exists(self, model_name: str):
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        try:
            if model_name.startswith("gpt-oss") or model_name.startswith("openai"):
                # é›²ç«¯æ¨¡å‹ï¼Œå‡è¨­å­˜åœ¨
                pass
            else:
                # æœ¬åœ°æ¨¡å‹ï¼Œæª¢æŸ¥Ollama
                import subprocess
                result = subprocess.run(
                    ["ollama", "list"],
                    capture_output=True,
                    text=True
                )
                if model_name not in result.stdout:
                    print(f"âš ï¸  è­¦å‘Šï¼šæœ¬åœ°æ¨¡å‹å¯èƒ½ä¸å­˜åœ¨ï¼š{model_name}")
        except Exception as e:
            print(f"âš ï¸  æª¢æŸ¥æ¨¡å‹å¤±æ•—ï¼š{e}")

# ä½¿ç”¨ç¤ºä¾‹
validator = ConfigValidator()

# é©—è­‰é…ç½®æ–‡ä»¶
result = validator.validate_config("~/.config/gpt-oss/config.yaml")
print(f"é©—è­‰çµæœï¼š{result['valid']}")

if not result['valid']:
    print("\nè«‹ä¿®æ­£é…ç½®æ–‡ä»¶å¾Œé‡æ–°é©—è­‰")
```

## ğŸ”§ ç¶­è­·è…³æœ¬

### è‡ªå‹•åŒ–ç¶­è­·

#### ç³»çµ±å¥åº·æª¢æŸ¥
```bash
#!/bin/bash
# health_check.sh - ç³»çµ±å¥åº·æª¢æŸ¥è…³æœ¬

echo "ğŸ¥ ç³»çµ±å¥åº·æª¢æŸ¥é–‹å§‹..."

# 1. æª¢æŸ¥Ollamaæœå‹™
echo "1. æª¢æŸ¥Ollamaæœå‹™..."
if pgrep -x "ollama" > /dev/null; then
    echo "   âœ… Ollamaæœå‹™é‹è¡Œæ­£å¸¸"
else
    echo "   âŒ Ollamaæœå‹™æœªé‹è¡Œ"
    echo "   å˜—è©¦å•Ÿå‹•æœå‹™..."
    ollama serve &
    sleep 10
fi

# 2. æª¢æŸ¥ç£ç¢Ÿç©ºé–“
echo "2. æª¢æŸ¥ç£ç¢Ÿç©ºé–“..."
DISK_USAGE=$(df -h ~/.ollama | tail -1 | awk '{print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
    echo "   âš ï¸  ç£ç¢Ÿä½¿ç”¨ç‡éé«˜ï¼š${DISK_USAGE}%"
    echo "   å»ºè­°æ¸…ç†ç·©å­˜æ–‡ä»¶"
else
    echo "   âœ… ç£ç¢Ÿç©ºé–“å……è¶³ï¼š${DISK_USAGE}%"
fi

# 3. æª¢æŸ¥å…§å­˜ä½¿ç”¨
echo "3. æª¢æŸ¥å…§å­˜ä½¿ç”¨..."
MEMORY_USAGE=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100.0}')
if [ $MEMORY_USAGE -gt 80 ]; then
    echo "   âš ï¸  å…§å­˜ä½¿ç”¨ç‡éé«˜ï¼š${MEMORY_USAGE}%"
    echo "   å»ºè­°é‡å•ŸOllamaæœå‹™"
else
    echo "   âœ… å…§å­˜ä½¿ç”¨æ­£å¸¸ï¼š${MEMORY_USAGE}%"
fi

# 4. æª¢æŸ¥æ¨¡å‹å®Œæ•´æ€§
echo "4. æª¢æŸ¥æ¨¡å‹å®Œæ•´æ€§..."
OLLAMA_LIST=$(ollama list)
if [ -z "$OLLAMA_LIST" ]; then
    echo "   âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹"
else
    echo "   âœ… å·²æ‰¾åˆ°ä»¥ä¸‹æ¨¡å‹ï¼š"
    echo "$OLLAMA_LIST"
fi

# 5. æª¢æŸ¥APIé€£æ¥
echo "5. æª¢æŸ¥APIé€£æ¥..."
if curl -s http://localhost:11434/api/version > /dev/null; then
    echo "   âœ… APIé€£æ¥æ­£å¸¸"
else
    echo "   âŒ APIé€£æ¥å¤±æ•—"
fi

# 6. æ¸…ç†è‡¨æ™‚æ–‡ä»¶
echo "6. æ¸…ç†è‡¨æ™‚æ–‡ä»¶..."
find ~/.ollama/logs -name "*.log" -mtime +7 -delete
echo "   âœ… è‡¨æ™‚æ–‡ä»¶å·²æ¸…ç†"

echo "ğŸ¥ ç³»çµ±å¥åº·æª¢æŸ¥å®Œæˆ"
```

### å‚™ä»½æ¢å¾©è…³æœ¬

#### é…ç½®å‚™ä»½
```python
# backup_system.py
import json
import yaml
import shutil
from datetime import datetime
from pathlib import Path
import tarfile

class BackupManager:
    def __init__(self, backup_dir: str):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
    
    def backup_configurations(self) -> str:
        """å‚™ä»½æ‰€æœ‰é…ç½®æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"config_backup_{timestamp}"
        backup_path = self.backup_dir / backup_name
        
        print(f"é–‹å§‹å‚™ä»½é…ç½®åˆ°ï¼š{backup_path}")
        backup_path.mkdir(exist_ok=True)
        
        # å‚™ä»½Ollamaé…ç½®
        ollama_config = Path.home() / ".ollama"
        if ollama_config.exists():
            shutil.copytree(ollama_config, backup_path / "ollama")
            print("   âœ… Ollamaé…ç½®å·²å‚™ä»½")
        
        # å‚™ä»½GPT-ossé…ç½®
        gpt_config = Path.home() / ".config" / "gpt-oss"
        if gpt_config.exists():
            shutil.copytree(gpt_config, backup_path / "gpt-oss")
            print("   âœ… GPT-ossé…ç½®å·²å‚™ä»½")
        
        # å‚™ä»½Obsidiané…ç½®
        obsidian_config = Path.home() / ".config" / "obsidian"
        if obsidian_config.exists():
            shutil.copytree(obsidian_config, backup_path / "obsidian")
            print("   âœ… Obsidiané…ç½®å·²å‚™ä»½")
        
        # å‰µå»ºå‚™ä»½æ¸…å–®
        backup_list = self._create_backup_list(backup_path)
        with open(backup_path / "backup_list.txt", 'w', encoding='utf-8') as f:
            f.write(backup_list)
        
        # å£“ç¸®å‚™ä»½
        backup_file = self._create_backup_archive(backup_path)
        
        print(f"âœ… é…ç½®å‚™ä»½å®Œæˆï¼š{backup_file}")
        return backup_file
    
    def _create_backup_list(self, backup_path: Path) -> str:
        """å‰µå»ºå‚™ä»½æ¸…å–®"""
        backup_list = f"å‚™ä»½æ™‚é–“ï¼š{datetime.now().isoformat()}\n\n"
        backup_list += "å‚™ä»½æ–‡ä»¶ï¼š\n"
        
        for item in backup_path.rglob("*"):
            if item.is_file():
                backup_list += f"- {item.relative_to(backup_path)}\n"
        
        return backup_list
    
    def _create_backup_archive(self, backup_path: Path) -> str:
        """å‰µå»ºå‚™ä»½å£“ç¸®åŒ…"""
        archive_name = f"{backup_path}.tar.gz"
        
        with tarfile.open(archive_name, "w:gz") as tar:
            for item in backup_path.rglob("*"):
                tar.add(item, arcname=item.relative_to(backup_path.parent))
        
        # åˆªé™¤è‡¨æ™‚å‚™ä»½ç›®éŒ„
        shutil.rmtree(backup_path)
        
        return archive_name
    
    def restore_configuration(self, backup_file: str) -> bool:
        """æ¢å¾©é…ç½®æ–‡ä»¶"""
        print(f"é–‹å§‹æ¢å¾©é…ç½®å¾ï¼š{backup_file}")
        
        backup_path = Path(backup_file)
        
        # è§£å£“å‚™ä»½
        with tarfile.open(backup_file, "r:gz") as tar:
            tar.extractall(path=self.backup_dir)
        
        # æ‰¾åˆ°å‚™ä»½ç›®éŒ„
        backup_dirs = [d for d in self.backup_dir.iterdir() if d.is_dir() and d.name.startswith("config_backup_")]
        if not backup_dirs:
            print("âŒ æœªæ‰¾åˆ°å‚™ä»½ç›®éŒ„")
            return False
        
        latest_backup = max(backup_dirs)
        print(f"æ‰¾åˆ°å‚™ä»½ç›®éŒ„ï¼š{latest_backup.name}")
        
        # æ¢å¾©é…ç½®
        ollama_backup = latest_backup / "ollama" / ".ollama"
        if ollama_backup.exists():
            shutil.copytree(ollama_backup, Path.home() / ".ollama", dirs_exist_ok=True)
            print("   âœ… Ollamaé…ç½®å·²æ¢å¾©")
        
        gpt_backup = latest_backup / "gpt-oss"
        if gpt_backup.exists():
            shutil.copytree(gpt_backup, Path.home() / ".config" / "gpt-oss", dirs_exist_ok=True)
            print("   âœ… GPT-ossé…ç½®å·²æ¢å¾©")
        
        obsidian_backup = latest_backup / "obsidian" / ".config" / "obsidian"
        if obsidian_backup.exists():
            shutil.copytree(obsidian_backup, Path.home() / ".config" / "obsidian", dirs_exist_ok=True)
            print("   âœ… Obsidiané…ç½®å·²æ¢å¾©")
        
        print("âœ… é…ç½®æ¢å¾©å®Œæˆ")
        return True

# ä½¿ç”¨ç¤ºä¾‹
backup_manager = BackupManager("~/backups")

# å‰µå»ºå‚™ä»½
backup_file = backup_manager.backup_configurations()

# æ¢å¾©é…ç½®
# backup_manager.restore_configuration(backup_file)
```

## ğŸ“Š ç›£æ§èˆ‡æ—¥èªŒ

### ç³»çµ±ç›£æ§å„€è¡¨æ¿

#### ç›£æ§æ•¸æ“šæ”¶é›†
```python
# monitoring_dashboard.py
import time
import psutil
import requests
from datetime import datetime, timedelta
from typing import Dict, List
import json

class MonitoringDashboard:
    def __init__(self, config):
        self.config = config
        self.metrics_history = []
    
    def collect_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†ç³»çµ±æŒ‡æ¨™"""
        timestamp = datetime.now().isoformat()
        
        metrics = {
            "timestamp": timestamp,
            "system": self._collect_system_metrics(),
            "api": self._collect_api_metrics(),
            "models": self._collect_model_metrics()
        }
        
        self.metrics_history.append(metrics)
        return metrics
    
    def _collect_system_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†ç³»çµ±æŒ‡æ¨™"""
        cpu = {
            "usage_percent": psutil.cpu_percent(interval=1),
            "load_average": list(psutil.getloadavg())
        }
        
        memory = psutil.virtual_memory()
        memory_metrics = {
            "total": memory.total,
            "available": memory.available,
            "percent": memory.percent,
            "used": memory.used,
            "free": memory.free
        }
        
        disk = psutil.disk_usage('/')
        disk_metrics = {
            "total": disk.total,
            "used": disk.used,
            "free": disk.free,
            "percent": disk.percent
        }
        
        network = psutil.net_io_counters()
        network_metrics = {
            "bytes_sent": network.bytes_sent,
            "bytes_recv": network.bytes_recv,
            "packets_sent": network.packets_sent,
            "packets_recv": network.packets_recv
        }
        
        return {
            "cpu": cpu,
            "memory": memory_metrics,
            "disk": disk_metrics,
            "network": network_metrics
        }
    
    def _collect_api_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†APIæŒ‡æ¨™"""
        metrics = {}
        
        # OllamaæŒ‡æ¨™
        try:
            start_time = time.time()
            response = requests.get("http://localhost:11434/api/version", timeout=5)
            ollama_latency = time.time() - start_time
            
            metrics["ollama"] = {
                "status": "online" if response.status_code == 200 else "offline",
                "latency": ollama_latency
            }
        except Exception:
            metrics["ollama"] = {
                "status": "offline",
                "latency": -1
            }
        
        # GPT-ossæŒ‡æ¨™
        try:
            start_time = time.time()
            response = requests.get(
                f"{self.config['gpt_oss']['base_url']}/models",
                headers={"Authorization": f"Bearer {self.config['gpt_oss']['api_key']}"},
                timeout=5
            )
            gpt_latency = time.time() - start_time
            
            metrics["gpt_oss"] = {
                "status": "online" if response.status_code == 200 else "offline",
                "latency": gpt_latency
            }
        except Exception:
            metrics["gpt_oss"] = {
                "status": "offline",
                "latency": -1
            }
        
        return metrics
    
    def _collect_model_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æ¨¡å‹æŒ‡æ¨™"""
        models = {}
        
        # Ollamaæ¨¡å‹
        try:
            import subprocess
            result = subprocess.run(
                ["ollama", "list"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                models["ollama_models"] = result.stdout
        except Exception as e:
            models["ollama_error"] = str(e)
        
        return models
    
    def generate_report(self) -> str:
        """ç”Ÿæˆç›£æ§å ±å‘Š"""
        if not self.metrics_history:
            return "æ²’æœ‰ç›£æ§æ•¸æ“š"
        
        latest_metrics = self.metrics_history[-1]
        
        report = f"""
ç³»çµ±ç›£æ§å ±å‘Š
{'='*50}

ç”Ÿæˆæ™‚é–“ï¼š{latest_metrics['timestamp']}

1. ç³»çµ±æŒ‡æ¨™
{'-'*40}
CPUä½¿ç”¨ç‡ï¼š{latest_metrics['system']['cpu']['usage_percent']}%
å¹³å‡è² è¼‰ï¼š{latest_metrics['system']['cpu']['load_average'][0]:.2f}
å…§å­˜ä½¿ç”¨ç‡ï¼š{latest_metrics['system']['memory']['percent']}%
ç£ç¢Ÿä½¿ç”¨ç‡ï¼š{latest_metrics['system']['disk']['percent']}%

2. APIç‹€æ…‹
{'-'*40}
Ollamaï¼š{'âœ… åœ¨ç·š' if latest_metrics['api']['ollama']['status'] == 'online' else 'âŒ é›¢ç·š'}
å»¶é²ï¼š{latest_metrics['api']['ollama']['latency']:.3f}ç§’

GPT-ossï¼š{'âœ… åœ¨ç·š' if latest_metrics['api']['gpt_oss']['status'] == 'online' else 'âŒ é›¢ç·š'}
å»¶é²ï¼š{latest_metrics['api']['gpt_oss']['latency']:.3f}ç§’

3. æ¨¡å‹ç‹€æ…‹
{'-'*40}
Ollamaæ¨¡å‹ï¼š{len(latest_metrics.get('models', {}).get('ollama_models', '').split()) if latest_metrics.get('models', {}).get('ollama_models') else 0}å€‹

4. å»ºè­°
{'-'*40}
"""
        
        # ç”Ÿæˆå„ªåŒ–å»ºè­°
        recommendations = []
        
        if latest_metrics['system']['cpu']['usage_percent'] > 80:
            recommendations.append("- CPUä½¿ç”¨ç‡éé«˜ï¼Œå»ºè­°æ¸›å°‘ä¸¦ç™¼ä»»å‹™")
        
        if latest_metrics['system']['memory']['percent'] > 80:
            recommendations.append("- å…§å­˜ä½¿ç”¨ç‡éé«˜ï¼Œå»ºè­°æ¸…ç†ç·©å­˜æˆ–å¢åŠ å…§å­˜")
        
        if latest_metrics['api']['ollama']['status'] == 'offline':
            recommendations.append("- Ollamaæœå‹™é›¢ç·šï¼Œå»ºè­°æª¢æŸ¥æœå‹™ç‹€æ…‹")
        
        if latest_metrics['api']['gpt_oss']['status'] == 'offline':
            recommendations.append("- GPT-oss APIç„¡æ³•è¨ªå•ï¼Œå»ºè­°æª¢æŸ¥ç¶²çµ¡å’ŒAPIå¯†é‘°")
        
        if recommendations:
            report += "\n".join(recommendations)
        else:
            report += "ç³»çµ±é‹è¡Œæ­£å¸¸ï¼Œç„¡éœ€å„ªåŒ–"
        
        report += f"\n{'='*50}"
        
        return report

# ä½¿ç”¨ç¤ºä¾‹
dashboard = MonitoringDashboard({
    "gpt_oss": {
        "base_url": "https://api.gpt-oss.com/v1",
        "api_key": "your-api-key"
    }
})

# æ”¶é›†æŒ‡æ¨™
metrics = dashboard.collect_metrics()

# ç”Ÿæˆå ±å‘Š
report = dashboard.generate_report()
print(report)
```

## âœ… æ•…éšœæ’é™¤æ¸…å–®

### ğŸ”§ ç³»çµ±æª¢æŸ¥
- [ ] æ‰€æœ‰æœå‹™æ­£å¸¸é‹è¡Œ
- [ ] é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¢º
- [ ] APIå¯†é‘°æœ‰æ•ˆä¸”æ¬Šé™æ­£ç¢º
- [ ] ç¶²çµ¡é€£æ¥æ­£å¸¸
- [ ] ç£ç¢Ÿç©ºé–“å……è¶³

### ğŸ”— é›†æˆæª¢æŸ¥
- [ ] Obsidian AIæ’ä»¶æ­£å¸¸å·¥ä½œ
- [ ] OpenCodeå¯ä»¥èª¿ç”¨AIæ¨¡å‹
- [ ] Ollamaæœå‹™éŸ¿æ‡‰æ­£å¸¸
- [ ] GPT-oss APIé€£æ¥æ­£å¸¸
- [ ] æ•¸æ“šåŒæ­¥åŠŸèƒ½æ­£å¸¸

### ğŸš€ æ€§èƒ½æª¢æŸ¥
- [ ] CPUä½¿ç”¨ç‡æ­£å¸¸
- [ ] å…§å­˜ä½¿ç”¨ç‡æ­£å¸¸
- [ ] APIéŸ¿æ‡‰æ™‚é–“æ­£å¸¸
- [ ] ä¸¦ç™¼è™•ç†èƒ½åŠ›æ­£å¸¸
- [ ] ç·©å­˜å‘½ä¸­ç‡è‰¯å¥½

## ğŸ æ”¯æ´èˆ‡å¹«åŠ©

### ğŸ“ æŠ€è¡“æ”¯æŒ
- **æ–‡æª”æ”¯æŒ**ï¼šæŸ¥çœ‹åœ¨ç·šæ–‡æª”
- **ç¤¾å€æ”¯æŒ**ï¼šåƒèˆ‡ç”¨æˆ¶ç¤¾å€è¨è«–
- **éƒµä»¶æ”¯æŒ**ï¼šç™¼é€éƒµä»¶è‡³æŠ€è¡“æ”¯æŒåœ˜éšŠ
- **åœ¨ç·šå®¢æœ**ï¼šä½¿ç”¨åœ¨ç·šå®¢æœç³»çµ±

### ğŸ“š çŸ¥è­˜åº«
- **å¸¸è¦‹å•é¡Œ**ï¼šæŸ¥é–±å¸¸è¦‹å•é¡Œè§£ç­”
- **æ•…éšœæ’é™¤**ï¼šåƒè€ƒæ•…éšœæ’é™¤æŒ‡å—
- **æœ€ä½³å¯¦è¸**ï¼šå­¸ç¿’æœ€ä½³å¯¦è¸æ–¹æ¡ˆ
- **ç”¨æˆ¶æ¡ˆä¾‹**ï¼šåƒè€ƒå…¶ä»–ç”¨æˆ¶çš„å¯¦è¸æ¡ˆä¾‹

---

## ğŸ‰ ç¸½çµ

é€šéæœ¬æŒ‡å—ï¼Œæ‚¨æ‡‰è©²èƒ½å¤ ï¼š

1. **ğŸ” è¨ºæ–·å’Œè§£æ±ºå¸¸è¦‹æ•…éšœ**
2. **âš¡ å„ªåŒ–ç³»çµ±æ€§èƒ½**
3. **ğŸ”§ ä¿®å¾©é…ç½®å•é¡Œ**
4. **ğŸ“Š ç›£æ§ç³»çµ±å¥åº·ç‹€æ³**
5. **ğŸ’¾ å‚™ä»½å’Œæ¢å¾©é…ç½®**

> ğŸ’¡ **æç¤º**ï¼šå»ºè­°å®šæœŸåŸ·è¡Œå¥åº·æª¢æŸ¥ï¼ŒåŠæ™‚ç™¼ç¾å’Œè§£æ±ºå•é¡Œã€‚

---

**ğŸ“ å‰µå»ºæ™‚é–“**ï¼š2026-01-21 | **ğŸ”„ æœ€å¾Œæ›´æ–°**ï¼š2026-01-21 | **ğŸ‘¥ ç¶­è­·è€…**ï¼šAI Integration Team