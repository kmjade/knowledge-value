# æŒ‡å—

# é…ç½®

## ğŸ“– æ¦‚è¿°

# çŸ¥è­˜

## ğŸŒŸ GPT-oss:120b-cloudç‰¹æ€§

### ğŸ§  æ ¸å¿ƒèƒ½åŠ›
| èƒ½åŠ›ç±»å‹ | è©³ç´°æè¿° | æ‡‰ç”¨ç¨‹å¼å ´æ™¯ |
|----------|----------|----------|
# åˆ†æ
| **ä»£ç¢¼ç”Ÿæˆ** | é«˜å“è³ªä»£ç¢¼ç”Ÿæˆå’Œå„ªåŒ– | ç·¨ç¨‹è¾…åŠ©ã€ä»£ç¢¼å¯©æŸ¥ |
# çŸ¥è­˜
| **å¤šè¯­è¨€æ”¯æŒ** | æ”¯æŒä¸­è‹±æ–‡ç­‰å¤šç§è¯­è¨€ | å›½é™…åŒ–æ‡‰ç”¨ç¨‹å¼ã€ç¿»è¯‘ |
# åˆ†æ

### âš¡ æ•ˆèƒ½å„ªå‹¢
- **é«˜ååé‡**ï¼šæ¯ç§’è™•ç†æ•°åƒä¸ªtoken
- **ä½å»¶é²**ï¼šå¹³å‡éŸ¿æ‡‰æ™‚é–“<500ms
- **é«˜å¯ç”¨æ€§**ï¼š99.9%æœåŠ¡å¯ç”¨æ€§
- **å¼¹æ€§æ“´å±•**ï¼šæ ¹æ®è´Ÿè½½è‡ªå‹•æ‰©å®¹

## ğŸ”‘ APIå¯†é’¥è·å–

### ğŸ“ è¨»å†Šå¸³æˆ¶

#### 1. è®¿é—®å®˜ç½‘
```bash
# è®¿é—®GPT-osså®˜ç½‘
https://cloud.gpt-oss.com
```

#### 2. å‰µå»ºå¸³æˆ¶
```bash
# è¨»å†Šæ–°ä½¿ç”¨è€…æµç¨‹
1. ç‚¹å‡»"ç«‹å³è¨»å†Š"
2. å¡«å¯«é‚®ç®±ã€å¯†ç¢¼
3. é©—è­‰é‚®ç®±åœ°å€
4. å®Œå–„ä¸ªäººè³‡è¨Š
5. é¸æ“‡å¥—é¤è¨ˆåŠƒ
```

#### 3. å®åè®¤è¯
```bash
# å®åè®¤è¯æ‰€éœ€ææ–™
- èº«ä»½è¯æ­£åé¢ç…§ç‰‡
- è”ç³»é›»è©±é©—è­‰
- é‚®ç®±é©—è­‰ç 
- äººè„¸è¯†åˆ«ï¼ˆå¯é€‰ï¼‰
```

# ç®¡ç†

#### ç”ŸæˆAPIå¯†é’¥
```bash
# ç”Ÿæˆæ–°APIå¯†é’¥
curl -X POST "https://api.gpt-oss.com/v1/keys" \
  -H "Authorization: Bearer YOUR_MASTER_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Obsidian Integration",
# çŸ¥è­˜åº«
    "permissions": ["read", "write"],
    "rate_limit": 1000
  }'
```

#### å¯†é’¥éŸ¿æ‡‰ç¤ºä¾‹
```json
{
  "key_id": "key_123456789",
  "api_key": "sk-gpt-oss-xxxxx-xxxxx-xxxxx",
  "created_at": "2026-01-21T10:00:00Z",
  "expires_at": "2027-01-21T10:00:00Z",
  "permissions": ["read", "write"],
  "rate_limit": 1000
}
```

#### å¯†é’¥å®‰å…¨å„²å­˜
```bash
# é…ç½®
mkdir -p ~/.config/gpt-oss
chmod 700 ~/.config/gpt-oss

# å‰µå»ºå¯†é’¥æª”æ¡ˆ
cat > ~/.config/gpt-oss/keys.json << EOF
{
  "production": "sk-gpt-oss-prod-xxxxx-xxxxx-xxxxx",
  "development": "sk-gpt-oss-dev-xxxxx-xxxxx-xxxxx",
  "test": "sk-gpt-oss-test-xxxxx-xxxxx-xxxxx"
}
EOF

# è¨­ç½®æª”æ¡ˆæƒé™
chmod 600 ~/.config/gpt-oss/keys.json
```

# é…ç½®

# é…ç½®

#### ç’°å¢ƒå˜é‡è¨­ç½®
```bash
# ~/.bashrc æˆ– ~/.zshrc
export GPT_OSS_API_KEY="sk-gpt-oss-xxxxx-xxxxx-xxxxx"
export GPT_OSS_BASE_URL="https://api.gpt-oss.com/v1"
export GPT_OSS_MODEL="gpt-oss-120b-cloud"
export GPT_OSS_TIMEOUT=30
export GPT_OSS_MAX_TOKENS=4096
```

# é…ç½®
```yaml
# ~/.config/gpt-oss/config.yaml
version: "1.0"
environment: "production"

# é…ç½®
api:
  base_url: "https://api.gpt-oss.com/v1"
  api_key: "${GPT_OSS_API_KEY}"
  model: "gpt-oss-120b-cloud"
  timeout: 30
  max_retries: 3
  retry_delay: 1

# è¯·æ±‚å‚æ•°
defaults:
  temperature: 0.7
  top_p: 0.9
  max_tokens: 4096
  stream: false
  presence_penalty: 0.0
  frequency_penalty: 0.0

# é«˜çº§è¨­ç½®
advanced:
  context_length: 8192
  response_format: "auto"
  user_id: "obsidian-user"
  session_id: "default"

# å®‰å…¨è¨­ç½®
security:
  validate_ssl: true
  check_content_policy: true
  filter_sensitive_data: true
```

# é…ç½®

#### SSLè¯ä¹¦é©—è­‰
```yaml
# é…ç½®
ssl:
  enabled: true
  verify_peer: true
  verify_host: true
  ca_bundle: "/etc/ssl/certs/ca-certificates.crt"
  cert_file: null
  key_file: null
```

#### è®¿é—®æ§åˆ¶
```yaml
# é…ç½®
access_control:
  allowed_origins:
    - "http://localhost:3000"
    - "https://yourdomain.com"
  
  allowed_ips:
    - "127.0.0.1"
    - "10.0.0.0/8"
    - "192.168.0.0/16"
  
  rate_limiting:
    enabled: true
    requests_per_minute: 60
    burst_size: 10
    penalty_duration: 300
```

## ğŸ”— ç³»çµ±æ•´åˆ

### ğŸ“ Obsidianæ•´åˆ

# é…ç½®
```yaml
# é…ç½®
text_generator:
  provider: "gpt-oss"
  api_key: "${GPT_OSS_API_KEY}"
  base_url: "https://api.gpt-oss.com/v1"
  model: "gpt-oss-120b-cloud"
  
  # ç”Ÿæˆå‚æ•°
  temperature: 0.7
  max_tokens: 2000
  top_p: 0.9
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # åŠŸèƒ½è¨­ç½®
  features:
    auto_complete: true
    smart_suggestions: true
    context_aware: true
    multi_language: true
  
  # ç•Œé¢è¨­ç½®
  ui:
    show_temperature: true
    show_model_selector: true
    confirm_before_generate: true
    streaming_response: false
```

#### æ™ºèƒ½ç­†è¨˜æ¨¡æ¿
```yaml
# AIå¢å¼ºç­†è¨˜æ¨¡æ¿
ai_note_template:
  name: "GPT-osså¢å¼ºç­†è¨˜"
  
  fields:
    - name: "title"
      type: "text"
      required: true
      ai_generated: false
    
    - name: "summary"
      type: "textarea"
      required: true
      ai_generated: true
      ai_prompt: "è¯·ä¸ºæ ‡é¢˜'{{title}}'ç”Ÿæˆä¸€ä¸ªç®€æ´çš„ç¸½çµ"
    
    - name: "key_points"
      type: "textarea"
      required: true
      ai_generated: true
      ai_prompt: "åŸºäºæ ‡é¢˜'{{title}}'å’Œç¸½çµ'{{summary}}'ï¼Œæå–3-5ä¸ªé—œéµè¦é»"
    
    - name: "tags"
      type: "text"
      required: false
      ai_generated: true
      ai_prompt: "ä¸ºæ ‡é¢˜'{{title}}'æ¨è3-5ä¸ªç›¸é—œæ¨™ç±¤ï¼Œç”¨é€—å·åˆ†éš”"
```

### ğŸ’» OpenCodeæ•´åˆ

# é…ç½®
```yaml
# é…ç½®
opencode:
  ai_provider: "gpt-oss"
  
  gpt_oss:
    api_key: "${GPT_OSS_API_KEY}"
    base_url: "https://api.gpt-oss.com/v1"
    model: "gpt-oss-120b-cloud"
    
    # ä»£ç¢¼ç”Ÿæˆå‚æ•°
    code_generation:
      temperature: 0.3
      max_tokens: 3000
      top_p: 0.9
      presence_penalty: 0.1
      frequency_penalty: 0.1
    
    # ä»£ç¢¼å¯©æŸ¥å‚æ•°
    code_review:
      temperature: 0.1
      max_tokens: 2000
      strict_mode: true
      security_check: true
    
    # æ–‡æª”ç”Ÿæˆå‚æ•°
    documentation:
      temperature: 0.4
      max_tokens: 2500
      style: "professional"
      language: "auto"
```

# é…ç½®
```python
# é…ç½®
class GPTOSSCodeAssistant:
    def __init__(self, api_key, base_url="https://api.gpt-oss.com/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self.model = "gpt-oss-120b-cloud"
    
    def generate_code(self, prompt, language="python", temperature=0.3):
        """ç”Ÿæˆä»£ç¢¼"""
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{language}ç¨‹å¼å‘˜ã€‚
è¯·æ ¹æ®éœ€æ±‚ç”Ÿæˆé«˜å“è³ªã€å¯è¯»æ€§å¼ºçš„ä»£ç¢¼ã€‚
ä»£ç¢¼æ‡‰è©²éµå¾ªæœ€ä½³å¯¦è¸å’Œç¼–ç è¦ç¯„ã€‚"""
        
        response = self._call_api(
            system_prompt=system_prompt,
            user_prompt=prompt,
            temperature=temperature
        )
        
        return response
    
    def review_code(self, code, language="python"):
        """ä»£ç¢¼å¯©æŸ¥"""
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„{language}ä»£ç¢¼å¯©æŸ¥ä¸“å®¶ã€‚
è¯·ä»ä»¥ä¸‹è§’åº¦å¯©æŸ¥ä»£ç¢¼ï¼š
1. ä»£ç¢¼å“è³ªå’Œå¯è¯»æ€§
2. æ•ˆèƒ½å„ªåŒ–å»ºè­°
3. å®‰å…¨æ€§å•é¡Œ
4. æœ€ä½³å¯¦è¸å»ºè­°"""
        
        response = self._call_api(
            system_prompt=system_prompt,
            user_prompt=f"è¯·å¯©æŸ¥ä»¥ä¸‹{language}ä»£ç¢¼ï¼š\n\n{code}",
            temperature=0.1
        )
        
        return response
    
    def explain_code(self, code, language="python"):
        """ä»£ç¢¼è§£é‡‹"""
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ª{language}æ•™å­¦ä¸“å®¶ã€‚
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡‹ä»£ç¢¼çš„åŠŸèƒ½å’ŒåŸç†ã€‚
é€‚åˆä¸åŒæ°´å¹³çš„é–‹ç™¼è€…ç†è§£ã€‚"""
        
        response = self._call_api(
            system_prompt=system_prompt,
            user_prompt=f"è¯·è§£é‡‹ä»¥ä¸‹{language}ä»£ç¢¼çš„åŠŸèƒ½ï¼š\n\n{code}",
            temperature=0.5
        )
        
        return response
```

### ğŸ¦™ Ollamaæ•´åˆ

# é…ç½®
```yaml
# é…ç½®
model_routing:
  # è·¯ç”±ç­–ç•¥
  strategy: "smart_routing"
  
# é…ç½®
  models:
    local:
      provider: "ollama"
      models:
        - "llama2:7b"
        - "codellama:7b"
      cost_per_token: 0.0
      max_tokens: 4096
      speed: "fast"
    
    cloud:
      provider: "gpt-oss"
      models:
        - "gpt-oss-120b-cloud"
      cost_per_token: 0.00002
      max_tokens: 8192
      speed: "medium"
  
  # è·¯ç”±è§„åˆ™
  routing_rules:
    - condition: "task_type == 'simple_chat'"
      target: "local"
      model: "llama2:7b"
    
    - condition: "task_type == 'code_simple'"
      target: "local"
      model: "codellama:7b"
    
    - condition: "task_type == 'complex_reasoning'"
      target: "cloud"
      model: "gpt-oss-120b-cloud"
    
    - condition: "token_count > 4000"
      target: "cloud"
      model: "gpt-oss-120b-cloud"
    
    - condition: "user_preference == 'quality_first'"
      target: "cloud"
      model: "gpt-oss-120b-cloud"
```

#### æ™ºèƒ½è·¯ç”±å¯¦ç¾
```python
# æ™ºèƒ½è·¯ç”±å¯¦ç¾
class SmartModelRouter:
    def __init__(self, routing_config):
        self.config = routing_config
        self.ollama_client = OllamaClient()
        self.gpt_oss_client = GPTOSSClient()
    
    def route_request(self, prompt, context=None):
        """æ™ºèƒ½è·¯ç”±è¯·æ±‚"""
# åˆ†æ
        task_type = self._analyze_task_type(prompt)
        token_count = self._estimate_tokens(prompt)
        user_preference = self._get_user_preference()
        
        # æ ¹æ®è·¯ç”±è§„åˆ™é¸æ“‡æ¨¡å‹
        target_model = self._select_model(
            task_type, token_count, user_preference
        )
        
        # ç™¼é€è¯·æ±‚
        if target_model["provider"] == "ollama":
            return self.ollama_client.generate(
                model=target_model["name"],
                prompt=prompt,
                context=context
            )
        else:
            return self.gpt_oss_client.generate(
                model=target_model["name"],
                prompt=prompt,
                context=context
            )
    
    def _analyze_task_type(self, prompt):
# åˆ†æ
        if "ä»£ç¢¼" in prompt or "ç·¨ç¨‹" in prompt:
            if "ç®€å•" in prompt or "åŸºç¤" in prompt:
                return "code_simple"
            else:
                return "code_complex"
# åˆ†æ
            return "complex_reasoning"
        else:
            return "simple_chat"
    
    def _estimate_tokens(self, text):
        """ä¼°ç®—tokenæ•°é‡"""
        return len(text) // 4  # ç®€å•ä¼°ç®—
    
    def _get_user_preference(self):
        """è·å–ä½¿ç”¨è€…åå¥½"""
        return self.config.get("user_preference", "balanced")
    
    def _select_model(self, task_type, token_count, user_preference):
        """é¸æ“‡æœ€ä¼˜æ¨¡å‹"""
        for rule in self.config["routing_rules"]:
            condition = rule["condition"]
            if self._evaluate_condition(condition, task_type, token_count, user_preference):
                return {
                    "provider": rule["target"],
                    "name": rule["model"]
                }
        
        # é»˜è®¤é¸æ“‡
        return {
            "provider": "local",
            "name": "llama2:7b"
        }
    
    def _evaluate_condition(self, condition, task_type, token_count, user_preference):
        """è©•ä¼°è·¯ç”±æ¡ä»¶"""
        # ç°¡åŒ–çš„æ¡ä»¶è©•ä¼°é€»è¾‘
        if "task_type" in condition:
            if condition["task_type"] == task_type:
                return True
        if "token_count" in condition:
            if token_count > int(condition["token_count"].split(">")[1]):
                return True
        if "user_preference" in condition:
            if condition["user_preference"] == user_preference:
                return True
        return False
```

# ç®¡ç†

### ğŸ’° å®šä»·ç­–ç•¥

#### è®¡è´¹æ¨¡å¼
| æœåŠ¡ç±»å‹ | ä»·æ ¼ | è®¡è´¹æ–¹å¼ | å…è²»é¢åº¦ |
|----------|------|----------|----------|
| **APIèª¿ç”¨** | Â¥0.02/1K tokens | æŒ‰é‡è®¡è´¹ | 100K tokens/æœˆ |
| **ä»£ç¢¼ç”Ÿæˆ** | Â¥0.025/1K tokens | æŒ‰é‡è®¡è´¹ | 50K tokens/æœˆ |
| **æ–‡æª”è™•ç†** | Â¥0.015/1K tokens | æŒ‰é‡è®¡è´¹ | 200K tokens/æœˆ |
| **æ‰¹é‡è™•ç†** | Â¥0.018/1K tokens | æŒ‰é‡è®¡è´¹ | 150K tokens/æœˆ |

#### å¥—é¤è¨ˆåŠƒ
```yaml
# é…ç½®
pricing_plans:
  free:
    name: "å…è²»ç‰ˆ"
    price: 0
    monthly_quota: 100000
    features:
      - "åŸºç¤APIè®¿é—®"
      - "æ¨™æº–éŸ¿æ‡‰é€Ÿåº¦"
      - "ç¤¾å€æ”¯æŒ"
    
  professional:
    name: "ä¸“ä¸šç‰ˆ"
    price: 99
    monthly_quota: 1000000
    features:
      - "ä¼˜å…ˆAPIè®¿é—®"
      - "å¿«é€ŸéŸ¿æ‡‰é€Ÿåº¦"
      - "é«˜çº§åŠŸèƒ½"
      - "é›»å­éƒµä»¶æ”¯æŒ"
    
  enterprise:
    name: "ä¼ä¸šç‰ˆ"
    price: 499
    monthly_quota: 10000000
    features:
      - "ä¸“äº«APIè®¿é—®"
      - "æé€ŸéŸ¿æ‡‰é€Ÿåº¦"
      - "å…¨éƒ¨é«˜çº§åŠŸèƒ½"
      - "ä¸“å±å®¢æˆ·ç»ç†"
      - "å®šåˆ¶åŒ–æœåŠ¡"
```

### ğŸ“ˆ ä½¿ç”¨ç›£æ§

#### æˆæœ¬ç›£æ§è…³æœ¬
```python
# cost_monitor.py
import requests
import json
from datetime import datetime, timedelta

class CostMonitor:
    def __init__(self, api_key, base_url="https://api.gpt-oss.com/v1"):
        self.api_key = api_key
        self.base_url = base_url
    
    def get_usage_stats(self, start_date, end_date):
        """è·å–ä½¿ç”¨çµ±è¨ˆ"""
        url = f"{self.base_url}/usage/stats"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        params = {
            "start_date": start_date,
            "end_date": end_date
        }
        
        response = requests.get(url, headers=headers, params=params)
        return response.json()
    
    def calculate_monthly_cost(self, year, month):
        """è¨ˆç®—æœˆåº¦æˆæœ¬"""
        start_date = f"{year}-{month:02d}-01"
        end_date = f"{year}-{month:02d}-31"
        
        stats = self.get_usage_stats(start_date, end_date)
        
        total_tokens = stats["total_tokens"]
        cost = self._calculate_cost(total_tokens)
        
        return {
            "month": f"{year}-{month:02d}",
            "total_tokens": total_tokens,
            "cost": cost,
            "free_quota_used": min(total_tokens, stats["free_quota"]),
            "paid_tokens": max(0, total_tokens - stats["free_quota"])
        }
    
    def _calculate_cost(self, tokens):
        """è¨ˆç®—æˆæœ¬"""
        if tokens <= 100000:  # å…è²»é¢åº¦
            return 0
        else:
            return (tokens - 100000) * 0.00002
    
    def generate_cost_report(self):
        """ç”Ÿæˆæˆæœ¬å ±å‘Š"""
        today = datetime.now()
        current_month = self.calculate_monthly_cost(today.year, today.month)
        
        # è·å–æœ€è¿‘6ä¸ªæœˆçš„æˆæœ¬
        report = {
            "current_month": current_month,
            "recent_months": []
        }
        
        for i in range(1, 7):
            date = today - timedelta(days=i*30)
            month_cost = self.calculate_monthly_cost(date.year, date.month)
            report["recent_months"].append(month_cost)
        
        return report
```

# é…ç½®
```yaml
# é…ç½®
budget_alerts:
  enabled: true
  
  # æœˆåº¦é¢„ç®—è¨­ç½®
  monthly_budget:
    amount: 500  # æœˆåº¦é¢„ç®—é™é¢
    warning_threshold: 0.8  # 80%æ—¶å‘Šè­¦
    critical_threshold: 0.95  # 95%æ—¶å‘Šè­¦
  
  # å‘Šè­¦æ–¹å¼
  alert_methods:
    email:
      enabled: true
      recipients:
        - "admin@company.com"
        - "finance@company.com"
      template: "budget_alert_email"
    
    webhook:
      enabled: true
      url: "https://yourcompany.com/webhooks/budget-alert"
      headers:
        Authorization: "Bearer your-webhook-token"
    
    slack:
      enabled: false
      webhook_url: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
  
  # å‘Šè­¦è¨Šæ¯æ¨¡æ¿
  templates:
    email:
      subject: "GPT-ossæœˆåº¦é¢„ç®—å‘Šè­¦ - {alert_level}"
      body: |
# ç®¡ç†
        
        æ‚¨çš„GPT-ossæœˆåº¦ä½¿ç”¨æƒ…å†µå¦‚ä¸‹ï¼š
        
        - æœˆåº¦é¢„ç®—ï¼š{monthly_budget}å…ƒ
        - å½“å‰æ¶ˆè´¹ï¼š{current_cost}å…ƒ
        - ä½¿ç”¨ç‡ï¼š{usage_percentage}%
        - å‰©ä½™é¢åº¦ï¼š{remaining_quota} tokens
        
        {alert_message}
        
        è¯·åŠæ—¶é—œæ³¨ä½¿ç”¨æƒ…å†µï¼Œé¿å…è¶…å‡ºé¢„ç®—ã€‚
        
# ç®¡ç†
```

## ğŸš€ é«˜çº§åŠŸèƒ½

# é…ç½®

#### ä»£ç¢¼ä¸“ç”¨æ¨¡å‹
```yaml
# é…ç½®
gpt_oss_code:
  model: "gpt-oss-120b-code"
  specialization: "code_generation"
  
  # ä»£ç¢¼ç”Ÿæˆå„ªåŒ–
  code_generation:
    languages:
      - "python"
      - "javascript"
      - "java"
      - "go"
      - "rust"
      - "cpp"
    
    frameworks:
      python:
        - "django"
        - "flask"
        - "fastapi"
        - "pandas"
        - "numpy"
      javascript:
        - "react"
        - "vue"
        - "angular"
        - "nodejs"
        - "express"
    
    quality_settings:
      follow_best_practices: true
      include_comments: true
      add_error_handling: true
      ensure_type_safety: true
```

#### æ–‡æª”ä¸“ç”¨æ¨¡å‹
```yaml
# é…ç½®
gpt_oss_docs:
  model: "gpt-oss-120b-docs"
  specialization: "documentation"
  
  # æ–‡æª”ç”Ÿæˆå„ªåŒ–
  documentation:
    formats:
      - "markdown"
      - "html"
      - "pdf"
      - "word"
    
    sections:
      required:
        - "title"
        - "introduction"
        - "usage"
        - "examples"
        - "api_reference"
    
    style_guides:
      technical:
        - "formal_tone"
        - "precise_terminology"
        - "clear_structure"
      user_friendly:
        - "conversational_tone"
        - "simple_explanations"
        - "practical_examples"
```

### ğŸ”„ æ‰¹é‡è™•ç†

#### æ‰¹é‡APIèª¿ç”¨
```python
# batch_processor.py
import asyncio
import aiohttp
import json
from typing import List, Dict

class BatchProcessor:
    def __init__(self, api_key, base_url="https://api.gpt-oss.com/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self.max_concurrent = 10  # å¹¶å‘é™åˆ¶
        self.semaphore = asyncio.Semaphore(self.max_concurrent)
    
    async def process_batch(self, requests: List[Dict], model="gpt-oss-120b-cloud"):
        """æ‰¹é‡è™•ç†è¯·æ±‚"""
        tasks = []
        for i, request in enumerate(requests):
            task = self._process_single_request(request, model, i)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results
    
    async def _process_single_request(self, request: Dict, model: str, index: int):
        """è™•ç†å•ä¸ªè¯·æ±‚"""
        async with self.semaphore:
            try:
                async with aiohttp.ClientSession() as session:
                    headers = {
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    }
                    
                    payload = {
                        "model": model,
                        "messages": request["messages"],
                        "temperature": request.get("temperature", 0.7),
                        "max_tokens": request.get("max_tokens", 4096)
                    }
                    
                    async with session.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=payload,
                        timeout=30
                    ) as response:
                        result = await response.json()
                        return {
                            "index": index,
                            "status": "success",
                            "result": result
                        }
            
            except Exception as e:
                return {
                    "index": index,
                    "status": "error",
                    "error": str(e)
                }
    
    async def process_text_batch(self, texts: List[str], prompt_template: str):
        """æ‰¹é‡è™•ç†æ–‡æœ¬"""
        requests = []
        for i, text in enumerate(texts):
            request = {
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬è™•ç†åŠ©æ‰‹ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt_template.format(text=text)
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 500
            }
            requests.append(request)
        
        results = await self.process_batch(requests)
        return results

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    processor = BatchProcessor(api_key="your-api-key")
    
    texts = [
        "Pythonæ˜¯ä¸€ç§ç·¨ç¨‹è¯­è¨€",
        "æœºå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
        "æ·±åº¦å­¸ç¿’ä½¿ç”¨ç¥ç»ç¶²è·¯"
    ]
    
    prompt_template = "è¯·ç¸½çµä»¥ä¸‹æ–‡æœ¬ï¼š{text}"
    
    results = await processor.process_text_batch(texts, prompt_template)
    
    for result in results:
        if result["status"] == "success":
            print(f"æ–‡æœ¬ {result['index']}: {result['result']['choices'][0]['message']['content']}")
        else:
            print(f"è™•ç†å¤±è´¥ {result['index']}: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())
```

### ğŸ”— APIä»£ç†

#### æœ¬åœ°APIä»£ç†
```python
# api_proxy.py
from flask import Flask, request, jsonify
import requests
import os

app = Flask(__name__)

class GPTOSSProxy:
    def __init__(self):
        self.api_key = os.getenv("GPT_OSS_API_KEY")
        self.base_url = "https://api.gpt-oss.com/v1"
        self.cache = {}
        self.cache_enabled = True
    
    def _get_cache_key(self, payload):
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        cache_str = json.dumps(payload, sort_keys=True)
        return hashlib.md5(cache_str.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key):
        """ä»ç¼“å­˜è·å–çµæœ"""
        if self.cache_enabled and cache_key in self.cache:
            return self.cache[cache_key]
        return None
    
    def _set_cache(self, cache_key, result):
        """è¨­ç½®ç¼“å­˜"""
        if self.cache_enabled:
            self.cache[cache_key] = result
    
    def _call_gpt_oss(self, payload):
        """èª¿ç”¨GPT-oss API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        return response.json()

gpt_oss = GPTOSSProxy()

@app.route("/v1/chat/completions", methods=["POST"])
def chat_completions():
    """ä»£ç†èŠå¤©å®Œæˆæ¥å£"""
    try:
        payload = request.json
        
        # æª¢æŸ¥ç¼“å­˜
        cache_key = gpt_oss._get_cache_key(payload)
        cached_result = gpt_oss._get_from_cache(cache_key)
        if cached_result:
            return jsonify(cached_result)
        
        # èª¿ç”¨API
        result = gpt_oss._call_gpt_oss(payload)
        
        # è¨­ç½®ç¼“å­˜
        gpt_oss._set_cache(cache_key, result)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/health", methods=["GET"])
def health_check():
    """å¥åº·æª¢æŸ¥"""
    return jsonify({"status": "healthy"})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080, debug=False)
```

# é…ç½®

# é…ç½®
- [ ] è·å–å¹¶é©—è­‰APIå¯†é’¥
- [ ] è¨­ç½®ç’°å¢ƒå˜é‡
# é…ç½®
- [ ] æ¸¬è©¦åŸºç¤APIèª¿ç”¨

# é…ç½®
# é…ç½®
# é…ç½®
# é…ç½®
- [ ] æ¸¬è©¦æ•´åˆåŠŸèƒ½

# ç®¡ç†
- [ ] äº†è§£å®šä»·ç­–ç•¥
- [ ] è¨­ç½®é¢„ç®—å‘Šè­¦
# éƒ¨ç½²
# é…ç½®

### ğŸš€ é«˜çº§åŠŸèƒ½
# é…ç½®
# éƒ¨ç½²
- [ ] è¨­ç½®APIä»£ç†
- [ ] æ¸¬è©¦é«˜çº§åŠŸèƒ½

## ğŸ¯ ä¸‹ä¸€æ­¥

# é…ç½®

1. **ğŸ“ åœ¨Obsidianä¸­ä½¿ç”¨GPT-oss**ï¼šé«”é©—æ™ºèƒ½ç­†è¨˜ç”Ÿæˆ
2. **ğŸ’» åœ¨OpenCodeä¸­ä½¿ç”¨**ï¼šäº«å—é«˜å“è³ªä»£ç¢¼ç”Ÿæˆ
# é…ç½®
4. **ğŸ“Š ç›£æ§ä½¿ç”¨æƒ…å†µ**ï¼šè·Ÿè¸ªæˆæœ¬å’Œæ•ˆèƒ½

# é…ç½®

---

# æ›´æ–°