---
title: 系統要求
date: 2026-01-22
# 配置
para: projects
status: in-progress
language: zh-cn
---

# 系統要求

> **章节**: 01-環境准备 | **难度**: ⭐ | **预计時間**: 30分钟

# 部署

---

## 💻 硬體要求

# 配置

# 配置
|-----|----------|------|
| **CPU** | 4核心 | 支持基本推理 |
| **記憶體** | 8GB | 适合小型模型 |
| **儲存** | 50GB SSD | 模型和數據儲存 |
| **GPU** | 可选 | CPU 推理可用 |

**适用場景**:
- ✅ 仅使用雲端模型
- ✅ 小型本地模型（7B 以下）
# 管理
- ❌ 复杂代碼生成
- ❌ 大型本地模型推理

# 配置

# 配置
|-----|----------|------|
| **CPU** | 8核心+ | 推理更流畅 |
| **記憶體** | 16GB+ | 支持中型模型 |
| **儲存** | 100GB+ NVMe SSD | 快速读写 |
| **GPU** | RTX 3060 12GB+ | 加速推理 |

**适用場景**:
# 部署
- ✅ 中型本地模型（7B-13B）
# 管理
- ✅ 实时 AI 交互

# 配置

# 配置
|-----|-----------|------|
| **CPU** | 12核心+ | 如 i7/i9 或 Ryzen 7/9 |
| **記憶體** | 32GB+ | 支持大型模型 |
| **儲存** | 200GB+ NVMe SSD | 模型库 + 數據 |
| **GPU** | RTX 4090 24GB | 大模型推理 |

**适用場景**:
- ✅ 大型本地模型（13B+）
# 部署
- ✅ 复杂 AI 任務
- ✅ 多模型并发

---

## 🛠️ 軟體要求

### 操作系統

# 版本
|-----|---------|---------|--------|
| **Windows** | Windows 10 | Windows 11 | ⭐⭐⭐⭐⭐ |
| **macOS** | macOS 11 | macOS 14 | ⭐⭐⭐⭐ |
| **Linux** | Ubuntu 20.04 | Ubuntu 24.04 | ⭐⭐⭐⭐⭐ |

### 必需軟體

# 版本
|-----|---------|---------|------|
# 管理
| **Node.js** | 16.x | 20.x LTS | 某些外掛依赖 |
# 版本
| **Python** | 3.8 | 3.10+ | Ollama 某些功能 |
# 部署

### 可选軟體

| 軟體 | 用途 | 必要性 |
|-----|------|-------|
| **VS Code** | 代碼編輯 | 推荐 |
# 管理
| **Postman** | API 測試 | 可选 |
| **Git GUI** | Git 客户端 | 可选 |

---

## 🌐 網路要求

### 带宽要求

| 使用場景 | 最低带宽 | 推荐带宽 |
|---------|---------|---------|
| **仅本地模型** | - | - |
| **雲端模型** | 10 Mbps | 50 Mbps+ |
| **大檔案下載** | 20 Mbps | 100 Mbps+ |

### 延遲要求

| 交互类型 | 最高延遲 | 推荐延遲 |
|---------|---------|---------|
| **实时对话** | 200ms | <100ms |
| **代碼生成** | 500ms | <200ms |
| **批量處理** | 1000ms | <500ms |

### 稳定性要求

- **可用性**: 99%+（雲端服务）
- **丢包率**: <0.1%
- **網路类型**: 宽带/Wi-Fi 5G/有线網路

---

# 配置

### 根据使用場景選擇

# 管理

# 配置
```
CPU: 4核心
記憶體: 8GB
儲存: 50GB SSD
網路: 10 Mbps+
```

**适用**:
# 整理
- 少量代碼辅助
- 预算有限

# 知識

# 配置
```
CPU: 8核心+
記憶體: 16GB+
儲存: 100GB+ NVMe SSD
GPU: RTX 3060 12GB+
網路: 50 Mbps+
```

**适用**:
# 管理
- 本地 + 雲端混合
- 性价比最优

#### 場景 3: 完全本地化

# 配置
```
CPU: 12核心+
記憶體: 32GB+
儲存: 200GB+ NVMe SSD
GPU: RTX 4090 24GB
網路: 100 Mbps+（用于下載）
```

**适用**:
- 隱私要求高
- 复杂 AI 任務
- 预算充足

---

## 🔍 環境檢查清單

在繼續之前，请檢查以下專案：

### 硬體檢查

- [x] CPU 核心数 ≥ 4 ✅ 2026-02-01
- [x] 記憶體 ≥ 8GB ✅ 2026-02-01
- [x] 可用儲存空間 ≥ 50GB ✅ 2026-02-01
- [ ] （可选）GPU 已安裝驅動程式

### 軟體檢查

- [x] 操作系統符合要求 ✅ 2026-02-01
- [x] Obsidian 已安裝或可安裝 ✅ 2026-02-01
- [x] Node.js 已安裝（`node --version`） ✅ 2026-02-01
- [x] Git 已安裝（`git --version`） ✅ 2026-02-01
- [ ] Python 已安裝（`python --version`）
- [ ] （可选）Docker 已安裝（`docker --version`）

### 網路檢查

- [ ] 網路連接正常
- [ ] 带宽符合要求
- [ ] （如使用雲端）防火墙允许 AI API 访问

---

## ⚠️ 常见問題

# 配置

**A**: 可以！建議：
- 使用雲端模型（GPT-oss:120b-cloud）
- 或使用小型本地模型（如 Llama-7B）
# 管理

### Q2: 没有 GPU，能運行本地模型吗？

**A**: 可以，但：
- 仅使用 CPU 推理，速度较慢
- 建議使用小型模型
- 或直接使用雲端模型

### Q3: 儲存空間不够怎么办？

**A**: 可以：
- 只安裝需要的模型
- 使用雲端模型作为主力
- 定期清理旧模型和數據

### Q4: 網路不稳定怎么办？

**A**: 建議：
- 优先使用本地模型
- 本地模型不需要網路
- 仅在下載模型时需要網路

---

## 📊 效能參考

### 模型推理速度參考

# 配置
|----------|---------|---------|
| CPU 4核 | 7B | 5-10 tokens/s |
| CPU 8核 | 7B | 10-20 tokens/s |
| RTX 3060 | 7B | 50-100 tokens/s |
| RTX 3060 | 13B | 25-50 tokens/s |
| RTX 4090 | 7B | 200+ tokens/s |
| RTX 4090 | 13B | 100+ tokens/s |

### 儲存空間需求

| 組件 | 大小 |
|-----|------|
| Obsidian + 外掛 | 500MB |
| OpenCode | 200MB |
| Ollama | 100MB |
| Llama-7B 模型 | 4GB |
| Llama-13B 模型 | 8GB |
# 知識庫
| **总计（推荐）** | **15-20GB** |

---

## 🚀 下一步

環境確認無误后，繼續下一步：

# 配置

---

## 📚 相關資源

# 指南
# 配置
- [[README.md]] - 返回仓库主页

---

# 更新
