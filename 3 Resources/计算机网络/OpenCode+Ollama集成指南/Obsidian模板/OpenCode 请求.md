---
tags:
  - opencode
  - ollama
  - local-ai
  - prompt
  - request
created: <% tp.file.creation_date() %>
---

# ğŸ¦™ OpenCode + Ollama æœ¬åœ°è¯·æ±‚ / Local Request

## ğŸ“‹ ä¸Šä¸‹æ–‡ä¿¡æ¯ / Context Information

> [!info] å½“å‰æ–‡ä»¶ / Current File
> - **è·¯å¾„**: `<% tp.file.path %>`
> - **æ ‡é¢˜**: `<% tp.file.title %>`
> - **åˆ›å»ºæ—¶é—´**: `<% tp.file.creation_date() %>`

<%*
// è·å–æ–‡ä»¶ä¸Šä¸‹æ–‡
const ctx = await tp.user.getOpenCodeContext(tp);
if (ctx) {
-%>

### ğŸ·ï¸ æ ‡ç­¾ / Tags
<% ctx.tags.map(t => `\`${t}\``).join(', ') %>

### ğŸ“ å‰ç½®å…ƒæ•°æ® / Frontmatter
```
<%*
    Object.entries(ctx.frontmatter).forEach(([key, value]) => {
        if (key !== 'tags') {
-%>
<% key %>: <% value %>
<%
        }
    });
-%>
```

### ğŸ“Š å†…å®¹ç»Ÿè®¡ / Content Statistics
| æŒ‡æ ‡ / Metric | å€¼ / Value |
|---------------|-----------|
| **å­—ç¬¦æ•° / Characters** | `<% ctx.charCount %>` |
| **æ®µè½æ•° / Paragraphs** | `<% ctx.content.split('\n\n').length %>` |
| **é“¾æ¥æ•° / Links** | `<% ctx.links.length %>` |
| **åˆ«åæ•° / Aliases** | `<% ctx.aliases.length %>` |

### ğŸ“„ æ–‡ä»¶é¢„è§ˆ / File Preview
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹å®Œæ•´å†…å®¹ / Click to view full content</summary>

```text
<% ctx.content.substring(0, 1000) %><% ctx.content.length > 1000 ? '\n\n...(å†…å®¹å·²æˆªæ–­ï¼Œå®Œæ•´å†…å®¹è¯·æŸ¥çœ‹åŸæ–‡ä»¶)' : '' %>
```
</details>

<%
} else {
-%>
> [!warning] æ— æ³•è·å–æ–‡ä»¶ä¸Šä¸‹æ–‡ / Cannot get file context
> è¯·ç¡®ä¿åœ¨æœ‰æ•ˆæ–‡ä»¶ä¸­è¿è¡Œæ­¤æ¨¡æ¿ / Please ensure running this template in a valid file
<%
}
-%>

---

## ğŸ¤– æ¨¡å‹é€‰æ‹© / Model Selection

<%*
// æ£€æŸ¥æœ¬åœ°æ¨¡å‹çŠ¶æ€
const modelStatus = await tp.user.checkLocalModels();
const task = await tp.user.selectTaskType(tp);

if (modelStatus.status === 'unavailable') {
-%>

> [!danger] OllamaæœåŠ¡ä¸å¯ç”¨ / Ollama Service Unavailable
> 
> **é”™è¯¯ä¿¡æ¯**: `<% modelStatus.error %>`
> 
> **è§£å†³æ–¹æ³•**:
> 1. å¯åŠ¨OllamaæœåŠ¡: `ollama serve`
> 2. æ£€æŸ¥ç«¯å£11434æ˜¯å¦è¢«å ç”¨
> 3. éªŒè¯Ollamaå®‰è£…: `ollama --version`

<%
} else {
    // æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    const availableModels = modelStatus.models.map(m => m.name);
    const selectedModel = await tp.system.suggester(
        availableModels,
        availableModels,
        false,
        'é€‰æ‹©æœ¬åœ°æ¨¡å‹ / Select local model:'
    );
    
    const recommendedModel = tp.user.recommendModel(task.type, task.requiresTools);
    const modelCapabilities = tp.user.getModelCapabilities(selectedModel);
-%>

### ğŸ¯ ä»»åŠ¡ä¿¡æ¯ / Task Information
| é¡¹ç›® / Item | å€¼ / Value |
|-----------|-----------|
| **ä»»åŠ¡ç±»å‹ / Task Type** | `<% task.name %>` |
| **éœ€è¦å·¥å…·ä½¿ç”¨ / Requires Tools** | `<% task.requiresTools ? 'æ˜¯ âœ…' : 'å¦ âŒ' %>` |
| **æ¨èæ¨¡å‹ / Recommended Model** | `<% recommendedModel %>` |
| **é€‰æ‹©æ¨¡å‹ / Selected Model** | `<% selectedModel %>` |

### ğŸ” æ¨¡å‹èƒ½åŠ› / Model Capabilities
<%*
const capabilities = [
    { name: 'å·¥å…·è°ƒç”¨ / Tool Usage', value: modelCapabilities.tools },
    { name: 'ä¸Šä¸‹æ–‡çª—å£ / Context Window', value: modelCapabilities.context + ' tokens' },
    { name: 'è´¨é‡ç­‰çº§ / Quality Level', value: modelCapabilities.quality }
];
-%>
<% capabilities.forEach(cap => { -%>
- **<% cap.name %>**: `<% cap.value ? 'âœ… ' + cap.value : 'âŒ ä¸æ”¯æŒ' %>`
<% }); -%>

<%*
if (task.requiresTools && !modelCapabilities.tools) {
-%>
> [!warning] âš ï¸ æ¨¡å‹ä¸æ”¯æŒå·¥å…·è°ƒç”¨ / Model Doesn't Support Tools
> å½“å‰é€‰æ‹©çš„æ¨¡å‹ä¸æ”¯æŒæ–‡ä»¶ä¿®æ”¹æ“ä½œã€‚è¯·æ›´æ¢ä¸ºæ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹ï¼š
> - **qwen2.5-coder:7b** - æ¨èé€‰æ‹©
> - **qwen2.5-coder:14b** - é«˜æ€§èƒ½é€‰æ‹©
> - **deepseek-coder:6.7b** - å¤‡é€‰æ–¹æ¡ˆ

<%
}
-%>

---
## ğŸ’¬ æŒ‡ä»¤è¾“å…¥ / Instructions

<%*
// ç”¨æˆ·æŒ‡ä»¤è¾“å…¥
const userPrompt = await tp.system.prompt(
    "è¯·è¾“å…¥å…·ä½“æŒ‡ä»¤ï¼ˆæ”¯æŒä¸­æ–‡/è‹±æ–‡ï¼‰ / Enter your instructions (Chinese/English supported):",
    task.type === 'generation' ? "ç”Ÿæˆ[å…·ä½“æè¿°]..." : "åˆ†æ/å¤„ç†[å…·ä½“ä»»åŠ¡]...",
    true
);

const command = tp.user.generateOpenCodeCommand(userPrompt, selectedModel, {
    noThink: task.type === 'generation' || task.type === 'refactoring',
    timeout: modelCapabilities.context > 16000 ? 300 : 120
});
-%>

### ğŸ“ æ‚¨çš„æŒ‡ä»¤ / Your Instructions
```text
<% userPrompt %>
```

### ğŸš€ OpenCode å‘½ä»¤ / OpenCode Command
<details>
<summary>ç‚¹å‡»å¤åˆ¶å‘½ä»¤ / Click to copy command</summary>

```bash
<% command %>
```

**å‘½ä»¤è§£æ / Command Analysis**:
<%*
const commandParts = [
    { name: 'åŸºç¡€å‘½ä»¤', value: 'opencode run' },
    { name: 'ä»»åŠ¡æè¿°', value: `"${userPrompt}"` },
    { name: 'æ¨¡å‹é€‰æ‹©', value: `--model ollama/${selectedModel}` }
];

if (task.type === 'generation') {
    commandParts.push({ name: 'æ€è€ƒæ¨¡å¼', value: '--no-think' });
}

if (modelCapabilities.context > 16000) {
    commandParts.push({ name: 'è¶…æ—¶æ—¶é—´', value: '--timeout 300' });
}
-%>
<% commandParts.forEach(part => { -%>
- **<% part.name %>**: `<% part.value %>`
<% }); -%>
</details>

---

## âš¡ æ€§èƒ½é¢„æœŸ / Performance Expectations

<%*
// æ ¹æ®æ¨¡å‹å’Œä»»åŠ¡ä¼°ç®—æ€§èƒ½
const performanceMap = {
    'qwen2.5-coder:14b': { min: '8-15', avg: '12', max: '20' },
    'qwen2.5-coder:7b': { min: '15-25', avg: '20', max: '35' },
    'qwen2.5:7b': { min: '20-35', avg: '28', max: '45' },
    'qwen2.5:3b': { min: '30-60', avg: '45', max: '80' },
    'mistral-nemo:12b': { min: '15-30', avg: '22', max: '40' }
};

const perf = performanceMap[selectedModel] || { min: '10-20', avg: '15', max: '30' };
const estimatedTime = task.requiresTools ? (parseInt(perf.avg) * 1.5) : perf.avg;
-%>

| æ¨¡å‹ / Model | é¢„æœŸæ—¶é—´ / Expected Time | è´¨é‡ / Quality | é€‚ç”¨åœºæ™¯ / Use Case |
|---------------|------------------------|---------------|-------------------|
| **<% selectedModel %>** | ~<% estimatedTime %>ç§’ | `<% modelCapabilities.quality %>` | `<% task.type.includes('generation') ? 'ä»£ç ç”Ÿæˆ' : task.type.includes('review') ? 'ä»£ç å®¡æŸ¥' : 'åˆ†æä»»åŠ¡' %>` |

> [!tip] ğŸ’¡ æ€§èƒ½æç¤º / Performance Tips
> - **é¦–æ¬¡è¿è¡Œ**å¯èƒ½è¾ƒæ…¢ï¼ˆæ¨¡å‹åŠ è½½æ—¶é—´ï¼‰
> - **å¤§ä¸Šä¸‹æ–‡**ä»»åŠ¡éœ€è¦æ›´å¤šæ—¶é—´
> - **å·¥å…·è°ƒç”¨**ä¼šé¢å¤–å¢åŠ å¤„ç†æ—¶é—´
> - **GPUä½¿ç”¨**ä¼šæ˜¾è‘—æå‡é€Ÿåº¦

---

## ğŸ“¤ æ‰§è¡Œæ­¥éª¤ / Execution Steps

> [!important] æœ¬åœ°æ‰§è¡Œæ­¥éª¤ / Local Execution Steps
> 
> ### ğŸ”§ å‡†å¤‡æ£€æŸ¥ / Preparation Check
> - [ ] **OllamaæœåŠ¡è¿è¡Œ**: `ollama serve`
> - [ ] **æ¨¡å‹å¯ç”¨**: `ollama list | grep <% selectedModel.split(':')[0] %>`
> - [ ] **ç«¯å£å¯ç”¨**: `curl -s http://localhost:11434/api/tags`
> - [ ] **å†…å­˜å……è¶³**: `free -h` æˆ–æ£€æŸ¥æ´»åŠ¨ç›‘è§†å™¨
> 
> ### ğŸš€ æ‰§è¡Œå‘½ä»¤ / Execute Command
> 1. å¤åˆ¶ä¸Šé¢ç”Ÿæˆçš„å‘½ä»¤ / Copy the command above
> 2. åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œ / Run in terminal
> 3. ç­‰å¾…å¤„ç†å®Œæˆ / Wait for completion
> 4. è§‚å¯Ÿè¾“å‡ºç»“æœ / Monitor output
> 
> ### ğŸ“‹ ç»“æœè®°å½• / Record Results
> - [ ] æˆåŠŸå®Œæˆ / Successfully completed
> - [ ] éƒ¨åˆ†æˆåŠŸ / Partially successful  
> - [ ] éœ€è¦é‡è¯• / Need to retry

---

## ğŸ“Š è¾“å‡ºç»“æœ / Output Results

> [!note] ğŸ“¤ ç»“æœç²˜è´´åŒº / Result Paste Area
> åœ¨æ­¤ç²˜è´´OpenCodeçš„è¿”å›ç»“æœ / Paste OpenCode response here

<details>
<summary>ç»“æœæ¨¡æ¿ / Result Template</summary>

### âœ… æ‰§è¡ŒçŠ¶æ€ / Execution Status
- **å¼€å§‹æ—¶é—´**: 
- **ç»“æŸæ—¶é—´**: 
- **æ€»è€—æ—¶**: 
- **æˆåŠŸåº¦**: 

### ğŸ“ AIè¾“å‡º / AI Output
```
[åœ¨æ­¤ç²˜è´´OpenCodeçš„è¿”å›ç»“æœ / Paste OpenCode response here]
```

### ğŸ” ç»“æœåˆ†æ / Result Analysis
- **è¾“å‡ºè´¨é‡**: 
- **æ˜¯å¦æ»¡è¶³éœ€æ±‚**: 
- **éœ€è¦æ”¹è¿›çš„åœ°æ–¹**: 

### ğŸ”„ åç»­è¡ŒåŠ¨ / Next Actions
- [ ] éœ€è¦è¿›ä¸€æ­¥ä¿®æ”¹
- [ ] ç”Ÿæˆç›¸å…³æ–‡æ¡£
- [ ] è¿›è¡Œæµ‹è¯•éªŒè¯
- [ ] é›†æˆåˆ°é¡¹ç›®ä¸­

</details>

---

## ğŸ”§ æ•…éšœæ’é™¤ / Troubleshooting

<details>
<summary>å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ / Common Issues & Solutions</summary>

### âŒ é—®é¢˜1: æ¨¡å‹æœªæ‰¾åˆ°
**ç—‡çŠ¶**: `Error: model not found`
**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥å¯ç”¨æ¨¡å‹
ollama list

# ä¸‹è½½ç¼ºå¤±æ¨¡å‹
ollama pull <% selectedModel %>

# éªŒè¯ä¸‹è½½
ollama show <% selectedModel %>
```

### âŒ é—®é¢˜2: è¿æ¥Ollamaå¤±è´¥
**ç—‡çŠ¶**: `Error: connection refused`
**è§£å†³æ–¹æ¡ˆ**:
```bash
# é‡å¯OllamaæœåŠ¡
pkill ollama && ollama serve &

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -an | grep 11434

# æµ‹è¯•è¿æ¥
curl http://localhost:11434/api/tags
```

### âŒ é—®é¢˜3: å†…å­˜ä¸è¶³
**ç—‡çŠ¶**: `Error: out of memory` æˆ–ç³»ç»Ÿå¡é¡¿
**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚qwen2.5:3bï¼‰
- å‡å°‘å¹¶å‘ä»»åŠ¡
- å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº
- é‡å¯ç³»ç»Ÿæ¸…ç†å†…å­˜

### âŒ é—®é¢˜4: å“åº”è¿‡æ…¢
**ç—‡çŠ¶**: å¤„ç†æ—¶é—´è¿‡é•¿ï¼ˆ>5åˆ†é’Ÿï¼‰
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥GPUæ˜¯å¦è¢«ä½¿ç”¨ï¼š`nvidia-smi`
- ä½¿ç”¨é‡åŒ–æ¨¡å‹
- å‡å°‘ä¸Šä¸‹æ–‡çª—å£å¤§å°
- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹

</details>

---

## ğŸ”— ç›¸å…³èµ„æº / Related Resources

### ğŸ“– æ–‡æ¡£é“¾æ¥ / Documentation Links
- **[OpenCodeå®˜æ–¹æ–‡æ¡£](https://opencode.ai/docs)** - å®Œæ•´ä½¿ç”¨æŒ‡å—
- **[Ollamaæ¨¡å‹åº“](https://ollama.ai/library)** - å¯ç”¨æ¨¡å‹åˆ—è¡¨
- **[æ¨¡å‹é…ç½®æŒ‡å—](opencode.json)** - é…ç½®æ–‡ä»¶è¯´æ˜

### ğŸ› ï¸ å¿«é€Ÿå‘½ä»¤ / Quick Commands
```bash
# æ£€æŸ¥æ¨¡å‹çŠ¶æ€
ollama list

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
ollama show <% selectedModel %>

# æµ‹è¯•OpenCodeè¿æ¥
opencode --version

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
opencode models
```

### ğŸ“š å­¦ä¹ èµ„æº / Learning Resources
- **[æœ¬åœ°AIæ•™ç¨‹](https://github.com/imagewize/ollama-opencode-setup)** - è¯¦ç»†è®¾ç½®æ•™ç¨‹
- **[æ¨¡å‹æ€§èƒ½å¯¹æ¯”](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)** - æ¨¡å‹æ’è¡Œæ¦œ
- **[OpenCodeç¤¾åŒº](https://opencode.ai/discord)** - ç”¨æˆ·äº¤æµç¤¾åŒº

---

## ğŸ“ æ›´æ–°æ—¥å¿— / Changelog

| ç‰ˆæœ¬ / Version | æ—¥æœŸ / Date | æ›´æ–°å†…å®¹ / Changes |
|---------------|-------------|-------------------|
| v1.0.0 | 2026-01-15 | åˆå§‹ç‰ˆæœ¬ / Initial version |

---

> [!success] ğŸ‰ æ¨¡æ¿ä½¿ç”¨æˆåŠŸ / Template Used Successfully
> æ‚¨å·²æˆåŠŸåˆ›å»ºOpenCodeæœ¬åœ°è¯·æ±‚æ–‡æ¡£ï¼ç°åœ¨å¯ä»¥ï¼š
> 1. å¤åˆ¶ä¸Šé¢çš„OpenCodeå‘½ä»¤
> 2. åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œ
> 3. å°†ç»“æœç²˜è´´åˆ°"è¾“å‡ºç»“æœ"åŒºåŸŸ
> 4. æ ¹æ®ç»“æœè¿›è¡Œåç»­æ“ä½œ

*æ­¤æ¨¡æ¿åŸºäºOpenCode + Ollamaæœ€ä½³å®è·µå¼€å‘ / This template is based on OpenCode + Ollama best practices*