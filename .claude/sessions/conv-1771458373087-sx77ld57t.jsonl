{"type":"meta","id":"conv-1771458373087-sx77ld57t","title":"备份后优化","createdAt":1771458373088,"updatedAt":1771458662702,"lastResponseAt":1771458453454,"sessionId":"8434f8bb-3a62-409a-a5d8-4668087bb18b","currentNote":"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md","usage":{"model":"claude-opus-4-6","inputTokens":7923,"cacheCreationInputTokens":0,"cacheReadInputTokens":74308,"contextWindow":200000,"contextTokens":82231,"percentage":41},"titleGenerationStatus":"failed"}
{"type":"message","message":{"id":"msg-1771458397258-6i2dgwi6w","role":"user","content":"备份后优化","timestamp":1771458397258,"currentNote":"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md"}}
{"type":"message","message":{"id":"msg-1771458397260-4mamxzgti","role":"assistant","content":"我会先备份这个文件,然后优化它。让我先读取文件内容来了解需要做什么优化。现在我将备份这个文件并进行优化。让我先备份,然后进行优化。备份完成。现在我将优化这个文档,主要改进包括:\n\n1. 移除外部网站的链接锚点文本\n2. 优化标题层级和格式\n3. 添加代码块标记\n4. 改进可读性和结构\n5. 添加适当的空行和格式完成!我已经完成了文件的备份和优化。主要改进包括:\n\n## 优化内容\n\n1. **移除了冗余的链接锚点文本** - 原文件中每个标题后面都有 `[](... \"永久链接至标题\")` 这样的文本,已全部清理\n\n2. **改进了标题结构** - 使用更清晰的二级标题(###)来组织每个小节的环境准备、运行方式等内容\n\n3. **添加了代码块标记** - 所有命令行和日志输出都用 ```bash ... ``` 包裹,提升了可读性和语法高亮\n\n4. **使用表格组织参数说明** - 将原本的列表形式改为更易读的表格形式\n\n5. **优化了空行和格式** - 增加了适当的空行分隔不同内容区块\n\n6. **修正了路径错误** - 修复了第265行的路径错误(原本写的是 decode2display 目录)\n\n7. **修复了参数说明错误** - 第281行的 `-width` 改为正确的 `-owidth`\n\n备份文件已保存在: [[5.1. 参考示例.backup.md]]","timestamp":1771458397260,"toolCalls":[{"id":"call_c0e2b318fe8e4f65b374b086","name":"Read","input":{"file_path":"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md"},"status":"completed","isExpanded":false,"result":"     1→\n     2→\n     3→# 5.1. 参考示例[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id1 \"永久链接至标题\")\n     4→\n     5→本章节将介绍基于`hobot-sp-cdev`多媒体库开发的多种功能示例，包括摄像头图像采集、视频编解码、视频显示、算法推理等功能。\n     6→\n     7→## 5.1.1. 安装[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id2 \"永久链接至标题\")\n     8→\n     9→首次使用功能示例时，需要在系统中安装`hobot-sp-cdev`多媒体库，命令如下：\n    10→\n    11→sudo apt update\n    12→sudo apt install hobot-sp-cdev\n    13→\n    14→头文件、库会安装在`/usr/include`、`/usr/lib`目录下，示例程序会安装在`/app/media_cdev`、`/app/bpu_cdev`目录下。文件列表如下：\n    15→\n    16→sunrise@ubuntu:~$ ls /usr/include/sp_*                              \n    17→/usr/include/sp_bpu.h  /usr/include/sp_codec.h  /usr/include/sp_display.h  /usr/include/sp_sys.h  /usr/include/sp_vio.h\n    18→\n    19→sunrise@ubuntu:~$ ls -l /usr/lib/libspcdev.so /usr/lib/libhb_dnn.so \n    20→-rw-r--r-- 1 root root  10280 Oct 31  2022 /usr/lib/libhb_dnn.so\n    21→-rw-r--r-- 1 root root 212056 Oct 31  2022 /usr/lib/libspcdev.so\n    22→\n    23→sunrise@ubuntu:/app$ tree bpu_cdev/ media_cdev/ -L 1\n    24→bpu_cdev/\n    25→├── go.sh\n    26→├── include\n    27→├── README.md\n    28→└── src\n    29→media_cdev/\n    30→├── decode2display\n    31→├── rtsp2display\n    32→├── vio2display\n    33→├── vio2encoder\n    34→└── vps\n    35→\n    36→## 5.1.2. 摄像头图像采集和显示[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id3 \"永久链接至标题\")\n    37→\n    38→本示例`vio2display`示例实现了`MIPI`摄像头图像采集功能，并通过`HDMI`接口输出，用户可通过显示器预览画面。示例流程框图如下：  \n    39→![image-vio_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_display.png)\n    40→\n    41→- **环境准备：**\n    42→    \n    43→    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n    44→        \n    45→    - 通过HDMI线缆连接开发板和显示器\n    46→        \n    47→    - 开发板上电，并通过命令行登录\n    48→        \n    49→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    50→    \n    51→    sunrise@ubuntu:~$ cd /app/media_cdev/vio2display\n    52→    sunrise@ubuntu:/app/media_cdev/vio2display$ sudo make\n    53→    sunrise@ubuntu:/app/media_cdev/vio2display$ sudo ./vio2display\n    54→    \n    55→- **预期效果：** 程序正确运行后，开发板会通过显示器输出`MIPI`摄像头采集的实时画面。运行log如下：\n    56→    \n    57→    sunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2display$ sudo ./vio2display\n    58→    [sudo] password for sunrise: \n    59→    disp_w=800, disp_h=480\n    60→    mipi_w:1920,mipi_h:1080;dst_w:800,dst_h:480;\n    61→    mipi_w:1920,mipi_h:1080;dst_w:1920,dst_h:1080;\n    62→    start linear mode, sensor_name f37, setting_size = 3\n    63→    sp_open_camera success!\n    64→    libiar: hb_disp_set_timing done![ 6156.771952] iar_output1_reqbufs.\n    65→    \n    66→    [ 6156.772663] iar_output_stream.\n    67→    \n    68→    Press 'q' to Exit !\n    69→    \n    70→\n    71→## 5.1.3. 摄像头图像本地保存[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id4 \"永久链接至标题\")\n    72→\n    73→本示例`vio_capture`示例实现了`MIPI`摄像头图像采集，并将`RAW`和`YUV`两种格式的图像本地保存的功能。示例流程框图如下：  \n    74→![image-capture](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-capture.png)\n    75→\n    76→- **环境准备：**\n    77→    \n    78→    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n    79→        \n    80→    - 通过HDMI线缆连接开发板和显示器\n    81→        \n    82→    - 开发板上电，并通过命令行登录\n    83→        \n    84→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    85→    \n    86→    sunrise@ubuntu:~$ cd /app/media_cdev/vio_capture/\n    87→    sunrise@ubuntu:/app/media_cdev/vio_capture$ sudo make\n    88→    sunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\n    89→    \n    90→    参数说明：\n    91→    \n    92→    - -b: RAW图bit数，IMX477：12，others：10\n    93→        \n    94→    - -c: 保存图像的数量\n    95→        \n    96→    - -w: 保持图像的宽度\n    97→        \n    98→    - -h: 保存图像的高度\n    99→        \n   100→- **预期效果：** 程序正确运行后，当前目录保存指定数量的图片文件，`RAW`格式以`raw_*.raw`方式命名，`YUV`格式以`yuv_*.yuv`方式命名。运行log如下：\n   101→    \n   102→    sunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\n   103→    Setting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n   104→    Setting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n   105→    jiale:start streaming...\n   106→    capture time :0\n   107→    capture time :1\n   108→    capture time :2\n   109→    capture time :3\n   110→    capture time :4\n   111→    capture time :5\n   112→    capture time :6\n   113→    capture time :7\n   114→    capture time :8\n   115→    capture time :9\n   116→    sensor_name imx477, setting_size = 1\n   117→    [  701.213210]hb_isp_algo_stop@main_user.c:389 GENERIC(ERR) :g_mutex destroy.\n   118→    \n   119→\n   120→## 5.1.4. 摄像头图像采集并编码[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id5 \"永久链接至标题\")\n   121→\n   122→本示例`vio2encoder`示例实现了 `MIPI` 摄像头图像采集功能，并编码后在本地保存，用户可通过显示器预览画面。示例流程框图如下：  \n   123→![image-vio_to_encoder](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_encoder.png)\n   124→\n   125→- **环境准备：**\n   126→    \n   127→    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n   128→        \n   129→    - 通过HDMI线缆连接开发板和显示器\n   130→        \n   131→    - 开发板上电，并通过命令行登录\n   132→        \n   133→- **运行方式：** 按照以下命令执行程序 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n   134→    \n   135→    sunrise@ubuntu:~$ cd /app/media_cdev/vio2encoder\n   136→    sunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo make\n   137→    sunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\n   138→    \n   139→    参数说明：\n   140→    \n   141→    - -w: 编码视频宽度\n   142→        \n   143→    - -h: 编码视频高度\n   144→        \n   145→    - -o: 编码输出路径\n   146→        \n   147→- **预期效果**： 程序正确运行后，在当前目录下会生成名为`stream.h264`的视频文件。运行log如下：\n   148→    \n   149→    sunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\n   150→    Setting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n   151→    Setting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n   152→    start linear mode, sensor_name f37, setting_size = 3\n   153→    sp_open_camera success!\n   154→    sp_start_encode success!\n   155→    sp_module_bind(vio -> encoder) success!\n   156→    \n   157→\n   158→## 5.1.5. 视频文件解码并显示[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id6 \"永久链接至标题\")\n   159→\n   160→本示例`decoder2display`实现了视频文件解码，并通过`HDMI`接口输出的工，用户可通过显示器预览画面。示例流程框图如下：  \n   161→![image-decoder_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-decoder_to_display.png)\n   162→\n   163→- **环境准备：**\n   164→    \n   165→    - 通过HDMI线缆连接开发板和显示器\n   166→        \n   167→    - 开发板上电，并通过命令行登录\n   168→        \n   169→    - 准备视频编码文件`stream.h264` 作为输入。\n   170→        \n   171→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n   172→    \n   173→    sunrise@ubuntu:~$ cd /app/media_cdev/decode2display\n   174→    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo make\n   175→    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./decoder2display -w 1920 -h 1080 -i stream.h264\n   176→    \n   177→    参数说明：\n   178→    \n   179→    - -h: 视频文件的高度\n   180→        \n   181→    - -w: 视频文件的宽度\n   182→        \n   183→    - -i: 视频文件的路径\n   184→        \n   185→- **预期效果：** 程序正确运行后，视频画面会通过开发板的`HDMI`接口输出，用户可以通过显示器预览视频画面。运行log如下：\n   186→    \n   187→    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo./decoder2display -w 1920 -h 1080 -i stream.h264\n   188→    disp_w=1024, disp_h=600\n   189→    [x3_av_open_stream]:[380]:probesize: 5000000\n   190→    sp_start_decode success!\n   191→    libiar: hb_disp_set_timing done!\n   192→    sp_start_display success!\n   193→    sp_open_vps success!\n   194→    \n   195→\n   196→## 5.1.6. RTSP拉流解码[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#rtsp \"永久链接至标题\")\n   197→\n   198→本示例`rtsp2display`实现了拉取`rtsp`码流、解码，并通过`HDMI`输出视频图像的功能，用户可通过显示器预览画面。示例流程框图如下：  \n   199→![rtsp2display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-rtsp_to_display.png)\n   200→\n   201→- **环境准备：**\n   202→    \n   203→    - 通过HDMI线缆连接开发板和显示器\n   204→        \n   205→    - 开发板上电，并通过命令行登录\n   206→        \n   207→    - 准备`rtsp`码流作为输入源\n   208→        \n   209→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n   210→    \n   211→    sunrise@ubuntu:~$ cd /app/media_cdev/rtsp2display\n   212→    sunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo make #可能会打印一些警告信息，无需理会\n   213→    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\n   214→    \n   215→    参数配置：\n   216→    \n   217→    - -i: 码流url地址\n   218→        \n   219→    - -t: 传输类型，可选tcp/udp\n   220→        \n   221→- **预期效果：** 程序正确运行后，视频画面会通过开发板的`HDMI`接口输出，用户可以通过显示器预览视频画面。运行log如下：\n   222→    \n   223→    sunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\n   224→    avformat_open_input ok!\n   225→    avformat_find_stream_info ok!\n   226→    Input #0, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n   227→      Metadata:\n   228→        title           : h264.mp4\n   229→      Duration: N/A, start: 0.040000, bitrate: N/A\n   230→        Stream #0:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n   231→        Stream #0:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\n   232→    Input #1, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n   233→      Metadata:\n   234→        title           : h264.mp4\n   235→      Duration: N/A, start: 0.040000, bitrate: N/A\n   236→        Stream #1:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n   237→        Stream #1:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\n   238→    av_dump_format ok!\n   239→    rtsp_w:1920,rtsp_h:1080\n   240→    display_w:1024,dispaly_h:600\n   241→    libiar: hb_disp_set_timing done!\n   242→    sp_open_vps success!\n   243→    \n   244→- **注意事项：**\n   245→    \n   246→    - 使用UDP协议传输码流时，可能出现因网络丢包导致的花屏现象，此时可切换成TCP协议传输解决。\n   247→        \n   248→\n   249→## 5.1.7. VPS缩放示例[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#vps \"永久链接至标题\")\n   250→\n   251→本示例实现了基于视频处理模块`VPS`的视频缩放功能，用户可通过显示器预览画面。\n   252→\n   253→- **环境准备：**\n   254→    \n   255→    - 通过HDMI线缆连接开发板和显示器\n   256→        \n   257→    - 开发板上电，并通过命令行登录\n   258→        \n   259→    - 准备图像(NV12)、视频文件(H264)作为输入\n   260→        \n   261→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n   262→    \n   263→    sunrise@ubuntu:~$ cd /app/media_cdev/vps\n   264→    sunrise@ubuntu:/app/media_cdev/vps$ sudo make\n   265→    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n   266→    \n   267→    **参数配置：**\n   268→    \n   269→    - -i: 待操作的文件路径\n   270→        \n   271→    - -iheight: 输入高度\n   272→        \n   273→    - -iwidth: 输入宽度\n   274→        \n   275→    - -m: 输入模式，1:视频流；2:NV12图片\n   276→        \n   277→    - -o: 输出路径\n   278→        \n   279→    - -oheight: 输出高度\n   280→        \n   281→    - -width: 输出宽度\n   282→        \n   283→    - -skip:（可选）对于视频流输入，调过开头的帧数\n   284→        \n   285→- **预期效果：** 程序正确运行后，当前目录会保存处理后的图像文件`outpu.yuv`。运行log如下：\n   286→    \n   287→    sunrise@ubuntu:/app/media_cdev/vps$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --ow\n   288→    idth 1280\n   289→    [x3_av_open_stream]:[380]:probesize: 5000000\n   290→    hb_vp_deinit success\n   291→    \n   292→\n   293→## 5.1.8. 目标检测算法—fcos[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#fcos \"永久链接至标题\")\n   294→\n   295→本示例基于`fcos`模型，实现了本地视频流的目标检测算法功能，用户可通过显示器预览检测结果。\n   296→\n   297→- **环境准备：**\n   298→    \n   299→    - 通过HDMI线缆连接开发板和显示器\n   300→        \n   301→    - 开发板上电，并通过命令行登录\n   302→        \n   303→    - 准备视频文件(H264)作为输入\n   304→        \n   305→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n   306→    \n   307→    sunrise@ubuntu:~$ cd /app/bpu_cdev/src\n   308→    sunrise@ubuntu:/app/bpu_cdev/src$ sudo make\n   309→    sunrise@ubuntu:/app/bpu_cdev/src$ cd bin \n   310→    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n   311→    \n   312→    **参数配置：**\n   313→    \n   314→    - -f: 模型文件路径\n   315→        \n   316→    - -h: 输入视频的高度\n   317→        \n   318→    - -w: 输入视频的宽度\n   319→        \n   320→    - -i: 输入视频的路径\n   321→        \n   322→    - -m: 模型类型，默认为1\n   323→        \n   324→- **预期效果：** 程序正确运行后，会通过`HDMI`接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行log如下：\n   325→    \n   326→    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n   327→    [BPU_PLAT]BPU Platform Version(1.3.1)!\n   328→    [HBRT] set log level as 0. version = 3.14.5\n   329→    [DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\n   330→    Model info:\n   331→    model_name: fcos_512x512_nv12Input count: 1input[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 512, 512, ), alignedShape:(1, 3, 512, 512, )\n   332→    Output count: 15Output[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 80, ), alignedShape:(1, 64, 64, 80, )\n   333→    Output[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 80, ), alignedShape:(1, 32, 32, 80, )\n   334→    Output[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 80, ), alignedShape:(1, 16, 16, 80, )\n   335→    Output[3]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 80, ), alignedShape:(1, 8, 8, 80, )\n   336→    Output[4]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 80, ), alignedShape:(1, 4, 4, 80, )\n   337→    Output[5]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 4, ), alignedShape:(1, 64, 64, 4, )\n   338→    Output[6]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 4, ), alignedShape:(1, 32, 32, 4, )\n   339→    Output[7]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 4, ), alignedShape:(1, 16, 16, 4, )\n   340→    Output[8]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 4, ), alignedShape:(1, 8, 8, 4, )\n   341→    Output[9]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 4, ), alignedShape:(1, 4, 4, 4, )\n   342→    Output[10]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 1, ), alignedShape:(1, 64, 64, 1, )\n   343→    Output[11]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 1, ), alignedShape:(1, 32, 32, 1, )\n   344→    Output[12]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 1, ), alignedShape:(1, 16, 16, 1, )\n   345→    Output[13]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 1, ), alignedShape:(1, 8, 8, 1, )\n   346→    Output[14]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 1, ), alignedShape:(1, 4, 4, 1, )\n   347→    libiar: hb_disp_set_timing done!\n   348→    dispaly init ret = 0\n   349→    vps open ret = 0\n   350→    module bind vps & display ret = 0\n   351→    display start ret = 0\n   352→    [x3_av_open_stream]:[380]:probesize: 5000000\n   353→    decode start ret = 0\n   354→    module bind decoder & vps ret = 0\n   355→    [ERROR][\"vdec\"][video/src/vdec_group.c:348] [8870.450264]vdec_channel_bump_thread[348]: VDEC_MODULE module try again\n   356→    \n   357→    [draw_rect]:[137]:========point is 0,return========\n   358→    fps:55.555556,processing time:18\n   359→    \n   360→\n   361→## 5.1.9. 目标检测算法—YOLOv5[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#yolov5 \"永久链接至标题\")\n   362→\n   363→本示例基于`YOLOv5`模型，实现了摄像头目标检测算法功能，用户可通过显示器预览检测结果。\n   364→\n   365→- **环境准备：**\n   366→    \n   367→    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n   368→        \n   369→    - 通过HDMI线缆连接开发板和显示器\n   370→        \n   371→    - 开发板上电，并通过命令行登录\n   372→        \n   373→- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n   374→    \n   375→    sunrise@ubuntu:~$ cd /app/bpu_cdev/src\n   376→    sunrise@ubuntu:/app/bpu_cdev/src$ sudo make\n   377→    sunrise@ubuntu:/app/bpu_cdev/src$ cd bin \n   378→    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n   379→    \n   380→    **参数配置：**\n   381→    \n   382→    - -f: 模型的路径\n   383→        \n   384→    - -m: 模型类型，默认为0\n   385→        \n   386→- **预期效果：** 程序正确运行后，会通过`HDMI`接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行log如下：\n   387→    \n   388→    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n   389→    [BPU_PLAT]BPU Platform Version(1.3.1)!\n   390→    [HBRT] set log level as 0. version = 3.14.5\n   391→    [DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\n   392→    Model info:\n   393→    model_name: yolov5_672x672_nv12Input count: 1input[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 672, 672, ), alignedShape:(1, 3, 672, 672, )\n   394→    Output count: 3Output[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 84, 84, 255, ), alignedShape:(1, 84, 84, 255, )\n   395→    Output[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 42, 42, 255, ), alignedShape:(1, 42, 42, 255, )\n   396→    Output[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 21, 21, 255, ), alignedShape:(1, 21, 21, 255, )\n   397→    Setting VPS channel-1: src_w:1920, src_h:1080; dst_w:672, dst_h:672;\n   398→    Setting VPS channel-3: src_w:1920, src_h:1080; dst_w:1024, dst_h:600;\n   399→    Setting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n   400→    start linear mode, sensor_name f37, setting_size = 3\n   401→    libiar: hb_disp_set_timing done!\n   402→    yolov5_do_post fps:11.627907,processing time :86\n   403→"},{"id":"call_9331ef47ec0046a69c886813","name":"Bash","input":{"command":"cp \"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md\" \"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.backup.md\"","description":"备份原文件"},"status":"completed","isExpanded":false,"result":"/c/Users/thinkpad/.bash_profile: line 1: $'\\377\\376export': command not found"},{"id":"call_f66e1b1946c14ea5811c9300","name":"Write","input":{"file_path":"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md","content":"# 5.1. 参考示例\n\n本章节将介绍基于 `hobot-sp-cdev` 多媒体库开发的多种功能示例，包括摄像头图像采集、视频编解码、视频显示、算法推理等功能。\n\n## 5.1.1. 安装\n\n首次使用功能示例时，需要在系统中安装 `hobot-sp-cdev` 多媒体库，命令如下：\n\n```bash\nsudo apt update\nsudo apt install hobot-sp-cdev\n```\n\n头文件、库会安装在 `/usr/include`、`/usr/lib` 目录下，示例程序会安装在 `/app/media_cdev`、`/app/bpu_cdev` 目录下。文件列表如下：\n\n```bash\nsunrise@ubuntu:~$ ls /usr/include/sp_*\n/usr/include/sp_bpu.h  /usr/include/sp_codec.h  /usr/include/sp_display.h  /usr/include/sp_sys.h  /usr/include/sp_vio.h\n\nsunrise@ubuntu:~$ ls -l /usr/lib/libspcdev.so /usr/lib/libhb_dnn.so\n-rw-r--r-- 1 root root  10280 Oct 31  2022 /usr/lib/libhb_dnn.so\n-rw-r--r-- 1 root root 212056 Oct 31  2022 /usr/lib/libspcdev.so\n\nsunrise@ubuntu:/app$ tree bpu_cdev/ media_cdev/ -L 1\nbpu_cdev/\n├── go.sh\n├── include\n├── README.md\n└── src\nmedia_cdev/\n├── decode2display\n├── rtsp2display\n├── vio2display\n├── vio2encoder\n└── vps\n```\n\n## 5.1.2. 摄像头图像采集和显示\n\n本示例 `vio2display` 实现了 `MIPI` 摄像头图像采集功能，并通过 `HDMI` 接口输出，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![image-vio_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_display.png)\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vio2display\nsunrise@ubuntu:/app/media_cdev/vio2display$ sudo make\nsunrise@ubuntu:/app/media_cdev/vio2display$ sudo ./vio2display\n```\n\n### 预期效果\n\n程序正确运行后，开发板会通过显示器输出 `MIPI` 摄像头采集的实时画面。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2display$ sudo ./vio2display\n[sudo] password for sunrise:\ndisp_w=800, disp_h=480\nmipi_w:1920,mipi_h:1080;dst_w:800,dst_h:480;\nmipi_w:1920,mipi_h:1080;dst_w:1920,dst_h:1080;\nstart linear mode, sensor_name f37, setting_size = 3\nsp_open_camera success!\nlibiar: hb_disp_set_timing done![ 6156.771952] iar_output1_reqbufs.\n\n[ 6156.772663] iar_output_stream.\n\nPress 'q' to Exit !\n```\n\n## 5.1.3. 摄像头图像本地保存\n\n本示例 `vio_capture` 实现了 `MIPI` 摄像头图像采集，并将 `RAW` 和 `YUV` 两种格式的图像本地保存的功能。\n\n**示例流程框图如下:**\n![image-capture](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-capture.png)\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vio_capture/\nsunrise@ubuntu:/app/media_cdev/vio_capture$ sudo make\nsunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\n```\n\n**参数说明:**\n\n| 参数 | 说明 |\n|------|------|\n| `-b` | RAW 图 bit 数，IMX477：12，others：10 |\n| `-c` | 保存图像的数量 |\n| `-w` | 保存图像的宽度 |\n| `-h` | 保存图像的高度 |\n\n### 预期效果\n\n程序正确运行后，当前目录保存指定数量的图片文件，`RAW` 格式以 `raw_*.raw` 方式命名，`YUV` 格式以 `yuv_*.yuv` 方式命名。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\nSetting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nSetting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\njiale:start streaming...\ncapture time :0\ncapture time :1\ncapture time :2\ncapture time :3\ncapture time :4\ncapture time :5\ncapture time :6\ncapture time :7\ncapture time :8\ncapture time :9\nsensor_name imx477, setting_size = 1\n[  701.213210]hb_isp_algo_stop@main_user.c:389 GENERIC(ERR) :g_mutex destroy.\n```\n\n## 5.1.4. 摄像头图像采集并编码\n\n本示例 `vio2encoder` 实现了 `MIPI` 摄像头图像采集功能，并编码后在本地保存，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![image-vio_to_encoder](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_encoder.png)\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vio2encoder\nsunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo make\nsunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\n```\n\n**参数说明:**\n\n| 参数 | 说明 |\n|------|------|\n| `-w` | 编码视频宽度 |\n| `-h` | 编码视频高度 |\n| `-o` | 编码输出路径 |\n\n### 预期效果\n\n程序正确运行后，在当前目录下会生成名为 `stream.h264` 的视频文件。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\nSetting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nSetting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nstart linear mode, sensor_name f37, setting_size = 3\nsp_open_camera success!\nsp_start_encode success!\nsp_module_bind(vio -> encoder) success!\n```\n\n## 5.1.5. 视频文件解码并显示\n\n本示例 `decoder2display` 实现了视频文件解码，并通过 `HDMI` 接口输出，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![image-decoder_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-decoder_to_display.png)\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备视频编码文件 `stream.h264` 作为输入\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/decode2display\nsunrise@ubuntu:/app/media_cdev/decode2display$ sudo make\nsunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./decoder2display -w 1920 -h 1080 -i stream.h264\n```\n\n**参数说明:**\n\n| 参数 | 说明 |\n|------|------|\n| `-h` | 视频文件的高度 |\n| `-w` | 视频文件的宽度 |\n| `-i` | 视频文件的路径 |\n\n### 预期效果\n\n程序正确运行后，视频画面会通过开发板的 `HDMI` 接口输出，用户可以通过显示器预览视频画面。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./decoder2display -w 1920 -h 1080 -i stream.h264\ndisp_w=1024, disp_h=600\n[x3_av_open_stream]:[380]:probesize: 5000000\nsp_start_decode success!\nlibiar: hb_disp_set_timing done!\nsp_start_display success!\nsp_open_vps success!\n```\n\n## 5.1.6. RTSP 拉流解码\n\n本示例 `rtsp2display` 实现了拉取 `rtsp` 码流、解码，并通过 `HDMI` 输出视频图像的功能，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![rtsp2display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-rtsp_to_display.png)\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备 `rtsp` 码流作为输入源\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/rtsp2display\nsunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo make  # 可能会打印一些警告信息，无需理会\nsunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-i` | 码流 url 地址 |\n| `-t` | 传输类型，可选 tcp/udp |\n\n### 预期效果\n\n程序正确运行后，视频画面会通过开发板的 `HDMI` 接口输出，用户可以通过显示器预览视频画面。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\navformat_open_input ok!\navformat_find_stream_info ok!\nInput #0, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n  Metadata:\n    title           : h264.mp4\n  Duration: N/A, start: 0.040000, bitrate: N/A\n    Stream #0:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n    Stream #0:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\nInput #1, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n  Metadata:\n    title           : h264.mp4\n  Duration: N/A, start: 0.040000, bitrate: N/A\n    Stream #1:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n    Stream #1:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\nav_dump_format ok!\nrtsp_w:1920,rtsp_h:1080\ndisplay_w:1024,dispaly_h:600\nlibiar: hb_disp_set_timing done!\nsp_open_vps success!\n```\n\n### 注意事项\n\n- 使用 UDP 协议传输码流时，可能出现因网络丢包导致的花屏现象，此时可切换成 TCP 协议传输解决。\n\n## 5.1.7. VPS 缩放示例\n\n本示例实现了基于视频处理模块 `VPS` 的视频缩放功能，用户可通过显示器预览画面。\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备图像(NV12)、视频文件(H264)作为输入\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vps\nsunrise@ubuntu:/app/media_cdev/vps$ sudo make\nsunrise@ubuntu:/app/media_cdev/vps$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-i` | 待操作的文件路径 |\n| `-iheight` | 输入高度 |\n| `-iwidth` | 输入宽度 |\n| `-m` | 输入模式，1:视频流；2:NV12图片 |\n| `-o` | 输出路径 |\n| `-oheight` | 输出高度 |\n| `-owidth` | 输出宽度 |\n| `-skip` | （可选）对于视频流输入，跳过开头的帧数 |\n\n### 预期效果\n\n程序正确运行后，当前目录会保存处理后的图像文件 `output.yuv`。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/vps$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n[x3_av_open_stream]:[380]:probesize: 5000000\nhb_vp_deinit success\n```\n\n## 5.1.8. 目标检测算法—FCOS\n\n本示例基于 `FCOS` 模型，实现了本地视频流的目标检测算法功能，用户可通过显示器预览检测结果。\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备视频文件(H264)作为输入\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/bpu_cdev/src\nsunrise@ubuntu:/app/bpu_cdev/src$ sudo make\nsunrise@ubuntu:/app/bpu_cdev/src$ cd bin\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-f` | 模型文件路径 |\n| `-h` | 输入视频的高度 |\n| `-w` | 输入视频的宽度 |\n| `-i` | 输入视频的路径 |\n| `-m` | 模型类型，默认为 1 |\n\n### 预期效果\n\n程序正确运行后，会通过 `HDMI` 接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n[BPU_PLAT]BPU Platform Version(1.3.1)!\n[HBRT] set log level as 0. version = 3.14.5\n[DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\nModel info:\nmodel_name: fcos_512x512_nv12\nInput count: 1\ninput[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 512, 512, ), alignedShape:(1, 3, 512, 512, )\nOutput count: 15\nOutput[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 80, ), alignedShape:(1, 64, 64, 80, )\nOutput[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 80, ), alignedShape:(1, 32, 32, 80, )\nOutput[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 80, ), alignedShape:(1, 16, 16, 80, )\nOutput[3]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 80, ), alignedShape:(1, 8, 8, 80, )\nOutput[4]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 80, ), alignedShape:(1, 4, 4, 80, )\nOutput[5]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 4, ), alignedShape:(1, 64, 64, 4, )\nOutput[6]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 4, ), alignedShape:(1, 32, 32, 4, )\nOutput[7]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 4, ), alignedShape:(1, 16, 16, 4, )\nOutput[8]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 4, ), alignedShape:(1, 8, 8, 4, )\nOutput[9]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 4, ), alignedShape:(1, 4, 4, 4, )\nOutput[10]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 1, ), alignedShape:(1, 64, 64, 1, )\nOutput[11]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 1, ), alignedShape:(1, 32, 32, 1, )\nOutput[12]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 1, ), alignedShape:(1, 16, 16, 1, )\nOutput[13]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 1, ), alignedShape:(1, 8, 8, 1, )\nOutput[14]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 1, ), alignedShape:(1, 4, 4, 1, )\nlibiar: hb_disp_set_timing done!\ndispaly init ret = 0\nvps open ret = 0\nmodule bind vps & display ret = 0\ndisplay start ret = 0\n[x3_av_open_stream]:[380]:probesize: 5000000\ndecode start ret = 0\nmodule bind decoder & vps ret = 0\n[ERROR][\"vdec\"][video/src/vdec_group.c:348] [8870.450264]vdec_channel_bump_thread[348]: VDEC_MODULE module try again\n\n[draw_rect]:[137]:========point is 0,return========\nfps:55.555556,processing time:18\n```\n\n## 5.1.9. 目标检测算法—YOLOv5\n\n本示例基于 `YOLOv5` 模型，实现了摄像头目标检测算法功能，用户可通过显示器预览检测结果。\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/bpu_cdev/src\nsunrise@ubuntu:/app/bpu_cdev/src$ sudo make\nsunrise@ubuntu:/app/bpu_cdev/src$ cd bin\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-f` | 模型的路径 |\n| `-m` | 模型类型，默认为 0 |\n\n### 预期效果\n\n程序正确运行后，会通过 `HDMI` 接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n[BPU_PLAT]BPU Platform Version(1.3.1)!\n[HBRT] set log level as 0. version = 3.14.5\n[DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\nModel info:\nmodel_name: yolov5_672x672_nv12\nInput count: 1\ninput[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 672, 672, ), alignedShape:(1, 3, 672, 672, )\nOutput count: 3\nOutput[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 84, 84, 255, ), alignedShape:(1, 84, 84, 255, )\nOutput[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 42, 42, 255, ), alignedShape:(1, 42, 42, 255, )\nOutput[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 21, 21, 255, ), alignedShape:(1, 21, 21, 255, )\nSetting VPS channel-1: src_w:1920, src_h:1080; dst_w:672, dst_h:672;\nSetting VPS channel-3: src_w:1920, src_h:1080; dst_w:1024, dst_h:600;\nSetting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nstart linear mode, sensor_name f37, setting_size = 3\nlibiar: hb_disp_set_timing done!\nyolov5_do_post fps:11.627907,processing time :86\n```\n"},"status":"completed","isExpanded":false,"result":"The file 4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md has been updated successfully.","diffData":{"filePath":"4 Archives/6 APPLIED SCIENCES. MEDICINE. TECHNOLOGY/62 Engineering/UGV01-X3/5. C C++开发指南/5.1. 参考示例.md","originalContent":"\n\n# 5.1. 参考示例[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id1 \"永久链接至标题\")\n\n本章节将介绍基于`hobot-sp-cdev`多媒体库开发的多种功能示例，包括摄像头图像采集、视频编解码、视频显示、算法推理等功能。\n\n## 5.1.1. 安装[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id2 \"永久链接至标题\")\n\n首次使用功能示例时，需要在系统中安装`hobot-sp-cdev`多媒体库，命令如下：\n\nsudo apt update\nsudo apt install hobot-sp-cdev\n\n头文件、库会安装在`/usr/include`、`/usr/lib`目录下，示例程序会安装在`/app/media_cdev`、`/app/bpu_cdev`目录下。文件列表如下：\n\nsunrise@ubuntu:~$ ls /usr/include/sp_*                              \n/usr/include/sp_bpu.h  /usr/include/sp_codec.h  /usr/include/sp_display.h  /usr/include/sp_sys.h  /usr/include/sp_vio.h\n\nsunrise@ubuntu:~$ ls -l /usr/lib/libspcdev.so /usr/lib/libhb_dnn.so \n-rw-r--r-- 1 root root  10280 Oct 31  2022 /usr/lib/libhb_dnn.so\n-rw-r--r-- 1 root root 212056 Oct 31  2022 /usr/lib/libspcdev.so\n\nsunrise@ubuntu:/app$ tree bpu_cdev/ media_cdev/ -L 1\nbpu_cdev/\n├── go.sh\n├── include\n├── README.md\n└── src\nmedia_cdev/\n├── decode2display\n├── rtsp2display\n├── vio2display\n├── vio2encoder\n└── vps\n\n## 5.1.2. 摄像头图像采集和显示[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id3 \"永久链接至标题\")\n\n本示例`vio2display`示例实现了`MIPI`摄像头图像采集功能，并通过`HDMI`接口输出，用户可通过显示器预览画面。示例流程框图如下：  \n![image-vio_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_display.png)\n\n- **环境准备：**\n    \n    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n        \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/media_cdev/vio2display\n    sunrise@ubuntu:/app/media_cdev/vio2display$ sudo make\n    sunrise@ubuntu:/app/media_cdev/vio2display$ sudo ./vio2display\n    \n- **预期效果：** 程序正确运行后，开发板会通过显示器输出`MIPI`摄像头采集的实时画面。运行log如下：\n    \n    sunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2display$ sudo ./vio2display\n    [sudo] password for sunrise: \n    disp_w=800, disp_h=480\n    mipi_w:1920,mipi_h:1080;dst_w:800,dst_h:480;\n    mipi_w:1920,mipi_h:1080;dst_w:1920,dst_h:1080;\n    start linear mode, sensor_name f37, setting_size = 3\n    sp_open_camera success!\n    libiar: hb_disp_set_timing done![ 6156.771952] iar_output1_reqbufs.\n    \n    [ 6156.772663] iar_output_stream.\n    \n    Press 'q' to Exit !\n    \n\n## 5.1.3. 摄像头图像本地保存[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id4 \"永久链接至标题\")\n\n本示例`vio_capture`示例实现了`MIPI`摄像头图像采集，并将`RAW`和`YUV`两种格式的图像本地保存的功能。示例流程框图如下：  \n![image-capture](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-capture.png)\n\n- **环境准备：**\n    \n    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n        \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/media_cdev/vio_capture/\n    sunrise@ubuntu:/app/media_cdev/vio_capture$ sudo make\n    sunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\n    \n    参数说明：\n    \n    - -b: RAW图bit数，IMX477：12，others：10\n        \n    - -c: 保存图像的数量\n        \n    - -w: 保持图像的宽度\n        \n    - -h: 保存图像的高度\n        \n- **预期效果：** 程序正确运行后，当前目录保存指定数量的图片文件，`RAW`格式以`raw_*.raw`方式命名，`YUV`格式以`yuv_*.yuv`方式命名。运行log如下：\n    \n    sunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\n    Setting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n    Setting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n    jiale:start streaming...\n    capture time :0\n    capture time :1\n    capture time :2\n    capture time :3\n    capture time :4\n    capture time :5\n    capture time :6\n    capture time :7\n    capture time :8\n    capture time :9\n    sensor_name imx477, setting_size = 1\n    [  701.213210]hb_isp_algo_stop@main_user.c:389 GENERIC(ERR) :g_mutex destroy.\n    \n\n## 5.1.4. 摄像头图像采集并编码[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id5 \"永久链接至标题\")\n\n本示例`vio2encoder`示例实现了 `MIPI` 摄像头图像采集功能，并编码后在本地保存，用户可通过显示器预览画面。示例流程框图如下：  \n![image-vio_to_encoder](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_encoder.png)\n\n- **环境准备：**\n    \n    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n        \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n- **运行方式：** 按照以下命令执行程序 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/media_cdev/vio2encoder\n    sunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo make\n    sunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\n    \n    参数说明：\n    \n    - -w: 编码视频宽度\n        \n    - -h: 编码视频高度\n        \n    - -o: 编码输出路径\n        \n- **预期效果**： 程序正确运行后，在当前目录下会生成名为`stream.h264`的视频文件。运行log如下：\n    \n    sunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\n    Setting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n    Setting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n    start linear mode, sensor_name f37, setting_size = 3\n    sp_open_camera success!\n    sp_start_encode success!\n    sp_module_bind(vio -> encoder) success!\n    \n\n## 5.1.5. 视频文件解码并显示[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#id6 \"永久链接至标题\")\n\n本示例`decoder2display`实现了视频文件解码，并通过`HDMI`接口输出的工，用户可通过显示器预览画面。示例流程框图如下：  \n![image-decoder_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-decoder_to_display.png)\n\n- **环境准备：**\n    \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n    - 准备视频编码文件`stream.h264` 作为输入。\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/media_cdev/decode2display\n    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo make\n    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./decoder2display -w 1920 -h 1080 -i stream.h264\n    \n    参数说明：\n    \n    - -h: 视频文件的高度\n        \n    - -w: 视频文件的宽度\n        \n    - -i: 视频文件的路径\n        \n- **预期效果：** 程序正确运行后，视频画面会通过开发板的`HDMI`接口输出，用户可以通过显示器预览视频画面。运行log如下：\n    \n    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo./decoder2display -w 1920 -h 1080 -i stream.h264\n    disp_w=1024, disp_h=600\n    [x3_av_open_stream]:[380]:probesize: 5000000\n    sp_start_decode success!\n    libiar: hb_disp_set_timing done!\n    sp_start_display success!\n    sp_open_vps success!\n    \n\n## 5.1.6. RTSP拉流解码[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#rtsp \"永久链接至标题\")\n\n本示例`rtsp2display`实现了拉取`rtsp`码流、解码，并通过`HDMI`输出视频图像的功能，用户可通过显示器预览画面。示例流程框图如下：  \n![rtsp2display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-rtsp_to_display.png)\n\n- **环境准备：**\n    \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n    - 准备`rtsp`码流作为输入源\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/media_cdev/rtsp2display\n    sunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo make #可能会打印一些警告信息，无需理会\n    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\n    \n    参数配置：\n    \n    - -i: 码流url地址\n        \n    - -t: 传输类型，可选tcp/udp\n        \n- **预期效果：** 程序正确运行后，视频画面会通过开发板的`HDMI`接口输出，用户可以通过显示器预览视频画面。运行log如下：\n    \n    sunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\n    avformat_open_input ok!\n    avformat_find_stream_info ok!\n    Input #0, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n      Metadata:\n        title           : h264.mp4\n      Duration: N/A, start: 0.040000, bitrate: N/A\n        Stream #0:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n        Stream #0:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\n    Input #1, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n      Metadata:\n        title           : h264.mp4\n      Duration: N/A, start: 0.040000, bitrate: N/A\n        Stream #1:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n        Stream #1:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\n    av_dump_format ok!\n    rtsp_w:1920,rtsp_h:1080\n    display_w:1024,dispaly_h:600\n    libiar: hb_disp_set_timing done!\n    sp_open_vps success!\n    \n- **注意事项：**\n    \n    - 使用UDP协议传输码流时，可能出现因网络丢包导致的花屏现象，此时可切换成TCP协议传输解决。\n        \n\n## 5.1.7. VPS缩放示例[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#vps \"永久链接至标题\")\n\n本示例实现了基于视频处理模块`VPS`的视频缩放功能，用户可通过显示器预览画面。\n\n- **环境准备：**\n    \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n    - 准备图像(NV12)、视频文件(H264)作为输入\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/media_cdev/vps\n    sunrise@ubuntu:/app/media_cdev/vps$ sudo make\n    sunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n    \n    **参数配置：**\n    \n    - -i: 待操作的文件路径\n        \n    - -iheight: 输入高度\n        \n    - -iwidth: 输入宽度\n        \n    - -m: 输入模式，1:视频流；2:NV12图片\n        \n    - -o: 输出路径\n        \n    - -oheight: 输出高度\n        \n    - -width: 输出宽度\n        \n    - -skip:（可选）对于视频流输入，调过开头的帧数\n        \n- **预期效果：** 程序正确运行后，当前目录会保存处理后的图像文件`outpu.yuv`。运行log如下：\n    \n    sunrise@ubuntu:/app/media_cdev/vps$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --ow\n    idth 1280\n    [x3_av_open_stream]:[380]:probesize: 5000000\n    hb_vp_deinit success\n    \n\n## 5.1.8. 目标检测算法—fcos[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#fcos \"永久链接至标题\")\n\n本示例基于`fcos`模型，实现了本地视频流的目标检测算法功能，用户可通过显示器预览检测结果。\n\n- **环境准备：**\n    \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n    - 准备视频文件(H264)作为输入\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/bpu_cdev/src\n    sunrise@ubuntu:/app/bpu_cdev/src$ sudo make\n    sunrise@ubuntu:/app/bpu_cdev/src$ cd bin \n    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n    \n    **参数配置：**\n    \n    - -f: 模型文件路径\n        \n    - -h: 输入视频的高度\n        \n    - -w: 输入视频的宽度\n        \n    - -i: 输入视频的路径\n        \n    - -m: 模型类型，默认为1\n        \n- **预期效果：** 程序正确运行后，会通过`HDMI`接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行log如下：\n    \n    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n    [BPU_PLAT]BPU Platform Version(1.3.1)!\n    [HBRT] set log level as 0. version = 3.14.5\n    [DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\n    Model info:\n    model_name: fcos_512x512_nv12Input count: 1input[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 512, 512, ), alignedShape:(1, 3, 512, 512, )\n    Output count: 15Output[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 80, ), alignedShape:(1, 64, 64, 80, )\n    Output[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 80, ), alignedShape:(1, 32, 32, 80, )\n    Output[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 80, ), alignedShape:(1, 16, 16, 80, )\n    Output[3]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 80, ), alignedShape:(1, 8, 8, 80, )\n    Output[4]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 80, ), alignedShape:(1, 4, 4, 80, )\n    Output[5]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 4, ), alignedShape:(1, 64, 64, 4, )\n    Output[6]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 4, ), alignedShape:(1, 32, 32, 4, )\n    Output[7]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 4, ), alignedShape:(1, 16, 16, 4, )\n    Output[8]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 4, ), alignedShape:(1, 8, 8, 4, )\n    Output[9]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 4, ), alignedShape:(1, 4, 4, 4, )\n    Output[10]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 1, ), alignedShape:(1, 64, 64, 1, )\n    Output[11]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 1, ), alignedShape:(1, 32, 32, 1, )\n    Output[12]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 1, ), alignedShape:(1, 16, 16, 1, )\n    Output[13]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 1, ), alignedShape:(1, 8, 8, 1, )\n    Output[14]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 1, ), alignedShape:(1, 4, 4, 1, )\n    libiar: hb_disp_set_timing done!\n    dispaly init ret = 0\n    vps open ret = 0\n    module bind vps & display ret = 0\n    display start ret = 0\n    [x3_av_open_stream]:[380]:probesize: 5000000\n    decode start ret = 0\n    module bind decoder & vps ret = 0\n    [ERROR][\"vdec\"][video/src/vdec_group.c:348] [8870.450264]vdec_channel_bump_thread[348]: VDEC_MODULE module try again\n    \n    [draw_rect]:[137]:========point is 0,return========\n    fps:55.555556,processing time:18\n    \n\n## 5.1.9. 目标检测算法—YOLOv5[](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/C_Develop/cdev_demo.html#yolov5 \"永久链接至标题\")\n\n本示例基于`YOLOv5`模型，实现了摄像头目标检测算法功能，用户可通过显示器预览检测结果。\n\n- **环境准备：**\n    \n    - 开发板断电状态下，将`MIPI`摄像头接入开发板，连接方法可参考[MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n        \n    - 通过HDMI线缆连接开发板和显示器\n        \n    - 开发板上电，并通过命令行登录\n        \n- **运行方式：** 示例代码以源码形式提供，需要使用`make`命令进行编译后运行，步骤如下：\n    \n    sunrise@ubuntu:~$ cd /app/bpu_cdev/src\n    sunrise@ubuntu:/app/bpu_cdev/src$ sudo make\n    sunrise@ubuntu:/app/bpu_cdev/src$ cd bin \n    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n    \n    **参数配置：**\n    \n    - -f: 模型的路径\n        \n    - -m: 模型类型，默认为0\n        \n- **预期效果：** 程序正确运行后，会通过`HDMI`接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行log如下：\n    \n    sunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n    [BPU_PLAT]BPU Platform Version(1.3.1)!\n    [HBRT] set log level as 0. version = 3.14.5\n    [DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\n    Model info:\n    model_name: yolov5_672x672_nv12Input count: 1input[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 672, 672, ), alignedShape:(1, 3, 672, 672, )\n    Output count: 3Output[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 84, 84, 255, ), alignedShape:(1, 84, 84, 255, )\n    Output[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 42, 42, 255, ), alignedShape:(1, 42, 42, 255, )\n    Output[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 21, 21, 255, ), alignedShape:(1, 21, 21, 255, )\n    Setting VPS channel-1: src_w:1920, src_h:1080; dst_w:672, dst_h:672;\n    Setting VPS channel-3: src_w:1920, src_h:1080; dst_w:1024, dst_h:600;\n    Setting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\n    start linear mode, sensor_name f37, setting_size = 3\n    libiar: hb_disp_set_timing done!\n    yolov5_do_post fps:11.627907,processing time :86\n","newContent":"# 5.1. 参考示例\n\n本章节将介绍基于 `hobot-sp-cdev` 多媒体库开发的多种功能示例，包括摄像头图像采集、视频编解码、视频显示、算法推理等功能。\n\n## 5.1.1. 安装\n\n首次使用功能示例时，需要在系统中安装 `hobot-sp-cdev` 多媒体库，命令如下：\n\n```bash\nsudo apt update\nsudo apt install hobot-sp-cdev\n```\n\n头文件、库会安装在 `/usr/include`、`/usr/lib` 目录下，示例程序会安装在 `/app/media_cdev`、`/app/bpu_cdev` 目录下。文件列表如下：\n\n```bash\nsunrise@ubuntu:~$ ls /usr/include/sp_*\n/usr/include/sp_bpu.h  /usr/include/sp_codec.h  /usr/include/sp_display.h  /usr/include/sp_sys.h  /usr/include/sp_vio.h\n\nsunrise@ubuntu:~$ ls -l /usr/lib/libspcdev.so /usr/lib/libhb_dnn.so\n-rw-r--r-- 1 root root  10280 Oct 31  2022 /usr/lib/libhb_dnn.so\n-rw-r--r-- 1 root root 212056 Oct 31  2022 /usr/lib/libspcdev.so\n\nsunrise@ubuntu:/app$ tree bpu_cdev/ media_cdev/ -L 1\nbpu_cdev/\n├── go.sh\n├── include\n├── README.md\n└── src\nmedia_cdev/\n├── decode2display\n├── rtsp2display\n├── vio2display\n├── vio2encoder\n└── vps\n```\n\n## 5.1.2. 摄像头图像采集和显示\n\n本示例 `vio2display` 实现了 `MIPI` 摄像头图像采集功能，并通过 `HDMI` 接口输出，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![image-vio_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_display.png)\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vio2display\nsunrise@ubuntu:/app/media_cdev/vio2display$ sudo make\nsunrise@ubuntu:/app/media_cdev/vio2display$ sudo ./vio2display\n```\n\n### 预期效果\n\n程序正确运行后，开发板会通过显示器输出 `MIPI` 摄像头采集的实时画面。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2display$ sudo ./vio2display\n[sudo] password for sunrise:\ndisp_w=800, disp_h=480\nmipi_w:1920,mipi_h:1080;dst_w:800,dst_h:480;\nmipi_w:1920,mipi_h:1080;dst_w:1920,dst_h:1080;\nstart linear mode, sensor_name f37, setting_size = 3\nsp_open_camera success!\nlibiar: hb_disp_set_timing done![ 6156.771952] iar_output1_reqbufs.\n\n[ 6156.772663] iar_output_stream.\n\nPress 'q' to Exit !\n```\n\n## 5.1.3. 摄像头图像本地保存\n\n本示例 `vio_capture` 实现了 `MIPI` 摄像头图像采集，并将 `RAW` 和 `YUV` 两种格式的图像本地保存的功能。\n\n**示例流程框图如下:**\n![image-capture](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-capture.png)\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vio_capture/\nsunrise@ubuntu:/app/media_cdev/vio_capture$ sudo make\nsunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\n```\n\n**参数说明:**\n\n| 参数 | 说明 |\n|------|------|\n| `-b` | RAW 图 bit 数，IMX477：12，others：10 |\n| `-c` | 保存图像的数量 |\n| `-w` | 保存图像的宽度 |\n| `-h` | 保存图像的高度 |\n\n### 预期效果\n\n程序正确运行后，当前目录保存指定数量的图片文件，`RAW` 格式以 `raw_*.raw` 方式命名，`YUV` 格式以 `yuv_*.yuv` 方式命名。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/vio_capture$ sudo ./capture -b 12 -c 10 -h 1080 -w 1920\nSetting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nSetting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\njiale:start streaming...\ncapture time :0\ncapture time :1\ncapture time :2\ncapture time :3\ncapture time :4\ncapture time :5\ncapture time :6\ncapture time :7\ncapture time :8\ncapture time :9\nsensor_name imx477, setting_size = 1\n[  701.213210]hb_isp_algo_stop@main_user.c:389 GENERIC(ERR) :g_mutex destroy.\n```\n\n## 5.1.4. 摄像头图像采集并编码\n\n本示例 `vio2encoder` 实现了 `MIPI` 摄像头图像采集功能，并编码后在本地保存，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![image-vio_to_encoder](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-vio_to_encoder.png)\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vio2encoder\nsunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo make\nsunrise@ubuntu:/app/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\n```\n\n**参数说明:**\n\n| 参数 | 说明 |\n|------|------|\n| `-w` | 编码视频宽度 |\n| `-h` | 编码视频高度 |\n| `-o` | 编码输出路径 |\n\n### 预期效果\n\n程序正确运行后，在当前目录下会生成名为 `stream.h264` 的视频文件。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/tmp/nfs/sp_cdev/media_cdev/vio2encoder$ sudo ./vio2encoder -w 1920 -h 1080 -o stream.h264\nSetting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nSetting VPS channel-1: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nstart linear mode, sensor_name f37, setting_size = 3\nsp_open_camera success!\nsp_start_encode success!\nsp_module_bind(vio -> encoder) success!\n```\n\n## 5.1.5. 视频文件解码并显示\n\n本示例 `decoder2display` 实现了视频文件解码，并通过 `HDMI` 接口输出，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![image-decoder_to_display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-decoder_to_display.png)\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备视频编码文件 `stream.h264` 作为输入\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/decode2display\nsunrise@ubuntu:/app/media_cdev/decode2display$ sudo make\nsunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./decoder2display -w 1920 -h 1080 -i stream.h264\n```\n\n**参数说明:**\n\n| 参数 | 说明 |\n|------|------|\n| `-h` | 视频文件的高度 |\n| `-w` | 视频文件的宽度 |\n| `-i` | 视频文件的路径 |\n\n### 预期效果\n\n程序正确运行后，视频画面会通过开发板的 `HDMI` 接口输出，用户可以通过显示器预览视频画面。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/decode2display$ sudo ./decoder2display -w 1920 -h 1080 -i stream.h264\ndisp_w=1024, disp_h=600\n[x3_av_open_stream]:[380]:probesize: 5000000\nsp_start_decode success!\nlibiar: hb_disp_set_timing done!\nsp_start_display success!\nsp_open_vps success!\n```\n\n## 5.1.6. RTSP 拉流解码\n\n本示例 `rtsp2display` 实现了拉取 `rtsp` 码流、解码，并通过 `HDMI` 输出视频图像的功能，用户可通过显示器预览画面。\n\n**示例流程框图如下:**\n![rtsp2display](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/_images/image-rtsp_to_display.png)\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备 `rtsp` 码流作为输入源\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/rtsp2display\nsunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo make  # 可能会打印一些警告信息，无需理会\nsunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-i` | 码流 url 地址 |\n| `-t` | 传输类型，可选 tcp/udp |\n\n### 预期效果\n\n程序正确运行后，视频画面会通过开发板的 `HDMI` 接口输出，用户可以通过显示器预览视频画面。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/rtsp2display$ sudo ./rtsp2display -i rtsp://admin:admin123@10.96.32.170:554/0 -t tcp\navformat_open_input ok!\navformat_find_stream_info ok!\nInput #0, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n  Metadata:\n    title           : h264.mp4\n  Duration: N/A, start: 0.040000, bitrate: N/A\n    Stream #0:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n    Stream #0:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\nInput #1, rtsp, from 'rtsp://admin:admin123@10.96.32.170:554/0':\n  Metadata:\n    title           : h264.mp4\n  Duration: N/A, start: 0.040000, bitrate: N/A\n    Stream #1:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1920x1080, 25 tbr, 90k tbn, 180k tbc\n    Stream #1:1: Audio: pcm_mulaw, 8000 Hz, 1 channels, s16, 64 kb/s\nav_dump_format ok!\nrtsp_w:1920,rtsp_h:1080\ndisplay_w:1024,dispaly_h:600\nlibiar: hb_disp_set_timing done!\nsp_open_vps success!\n```\n\n### 注意事项\n\n- 使用 UDP 协议传输码流时，可能出现因网络丢包导致的花屏现象，此时可切换成 TCP 协议传输解决。\n\n## 5.1.7. VPS 缩放示例\n\n本示例实现了基于视频处理模块 `VPS` 的视频缩放功能，用户可通过显示器预览画面。\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备图像(NV12)、视频文件(H264)作为输入\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/media_cdev/vps\nsunrise@ubuntu:/app/media_cdev/vps$ sudo make\nsunrise@ubuntu:/app/media_cdev/vps$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-i` | 待操作的文件路径 |\n| `-iheight` | 输入高度 |\n| `-iwidth` | 输入宽度 |\n| `-m` | 输入模式，1:视频流；2:NV12图片 |\n| `-o` | 输出路径 |\n| `-oheight` | 输出高度 |\n| `-owidth` | 输出宽度 |\n| `-skip` | （可选）对于视频流输入，跳过开头的帧数 |\n\n### 预期效果\n\n程序正确运行后，当前目录会保存处理后的图像文件 `output.yuv`。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/media_cdev/vps$ sudo ./vps -m 1 -i stream.h264 -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n[x3_av_open_stream]:[380]:probesize: 5000000\nhb_vp_deinit success\n```\n\n## 5.1.8. 目标检测算法—FCOS\n\n本示例基于 `FCOS` 模型，实现了本地视频流的目标检测算法功能，用户可通过显示器预览检测结果。\n\n### 环境准备\n\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n- 准备视频文件(H264)作为输入\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/bpu_cdev/src\nsunrise@ubuntu:/app/bpu_cdev/src$ sudo make\nsunrise@ubuntu:/app/bpu_cdev/src$ cd bin\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-f` | 模型文件路径 |\n| `-h` | 输入视频的高度 |\n| `-w` | 输入视频的宽度 |\n| `-i` | 输入视频的路径 |\n| `-m` | 模型类型，默认为 1 |\n\n### 预期效果\n\n程序正确运行后，会通过 `HDMI` 接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/fcos_512x512_nv12.bin -m 1 -i 1080p_.h264 -w 1920 -h 1080\n[BPU_PLAT]BPU Platform Version(1.3.1)!\n[HBRT] set log level as 0. version = 3.14.5\n[DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\nModel info:\nmodel_name: fcos_512x512_nv12\nInput count: 1\ninput[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 512, 512, ), alignedShape:(1, 3, 512, 512, )\nOutput count: 15\nOutput[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 80, ), alignedShape:(1, 64, 64, 80, )\nOutput[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 80, ), alignedShape:(1, 32, 32, 80, )\nOutput[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 80, ), alignedShape:(1, 16, 16, 80, )\nOutput[3]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 80, ), alignedShape:(1, 8, 8, 80, )\nOutput[4]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 80, ), alignedShape:(1, 4, 4, 80, )\nOutput[5]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 4, ), alignedShape:(1, 64, 64, 4, )\nOutput[6]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 4, ), alignedShape:(1, 32, 32, 4, )\nOutput[7]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 4, ), alignedShape:(1, 16, 16, 4, )\nOutput[8]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 4, ), alignedShape:(1, 8, 8, 4, )\nOutput[9]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 4, ), alignedShape:(1, 4, 4, 4, )\nOutput[10]: tensorLayout: 0 tensorType: 13 validShape:(1, 64, 64, 1, ), alignedShape:(1, 64, 64, 1, )\nOutput[11]: tensorLayout: 0 tensorType: 13 validShape:(1, 32, 32, 1, ), alignedShape:(1, 32, 32, 1, )\nOutput[12]: tensorLayout: 0 tensorType: 13 validShape:(1, 16, 16, 1, ), alignedShape:(1, 16, 16, 1, )\nOutput[13]: tensorLayout: 0 tensorType: 13 validShape:(1, 8, 8, 1, ), alignedShape:(1, 8, 8, 1, )\nOutput[14]: tensorLayout: 0 tensorType: 13 validShape:(1, 4, 4, 1, ), alignedShape:(1, 4, 4, 1, )\nlibiar: hb_disp_set_timing done!\ndispaly init ret = 0\nvps open ret = 0\nmodule bind vps & display ret = 0\ndisplay start ret = 0\n[x3_av_open_stream]:[380]:probesize: 5000000\ndecode start ret = 0\nmodule bind decoder & vps ret = 0\n[ERROR][\"vdec\"][video/src/vdec_group.c:348] [8870.450264]vdec_channel_bump_thread[348]: VDEC_MODULE module try again\n\n[draw_rect]:[137]:========point is 0,return========\nfps:55.555556,processing time:18\n```\n\n## 5.1.9. 目标检测算法—YOLOv5\n\n本示例基于 `YOLOv5` 模型，实现了摄像头目标检测算法功能，用户可通过显示器预览检测结果。\n\n### 环境准备\n\n- 开发板断电状态下，将 `MIPI` 摄像头接入开发板，连接方法可参考 [MIPI摄像头连接教程](https://developer.d-robotics.cc/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#mipi)\n- 通过 HDMI 线缆连接开发板和显示器\n- 开发板上电，并通过命令行登录\n\n### 运行方式\n\n示例代码以源码形式提供，需要使用 `make` 命令进行编译后运行，步骤如下：\n\n```bash\nsunrise@ubuntu:~$ cd /app/bpu_cdev/src\nsunrise@ubuntu:/app/bpu_cdev/src$ sudo make\nsunrise@ubuntu:/app/bpu_cdev/src$ cd bin\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n```\n\n**参数配置:**\n\n| 参数 | 说明 |\n|------|------|\n| `-f` | 模型的路径 |\n| `-m` | 模型类型，默认为 0 |\n\n### 预期效果\n\n程序正确运行后，会通过 `HDMI` 接口输出视频和算法检测渲染后的画面，用户可通过显示器预览。运行 log 如下：\n\n```bash\nsunrise@ubuntu:/app/bpu_cdev/src/bin$ sudo ./sample -f /app/model/basic/yolov5_672x672_nv12.bin -m 0\n[BPU_PLAT]BPU Platform Version(1.3.1)!\n[HBRT] set log level as 0. version = 3.14.5\n[DNN] Runtime version = 1.9.7_(3.14.5 HBRT)\nModel info:\nmodel_name: yolov5_672x672_nv12\nInput count: 1\ninput[0]: tensorLayout: 2 tensorType: 1 validShape:(1, 3, 672, 672, ), alignedShape:(1, 3, 672, 672, )\nOutput count: 3\nOutput[0]: tensorLayout: 0 tensorType: 13 validShape:(1, 84, 84, 255, ), alignedShape:(1, 84, 84, 255, )\nOutput[1]: tensorLayout: 0 tensorType: 13 validShape:(1, 42, 42, 255, ), alignedShape:(1, 42, 42, 255, )\nOutput[2]: tensorLayout: 0 tensorType: 13 validShape:(1, 21, 21, 255, ), alignedShape:(1, 21, 21, 255, )\nSetting VPS channel-1: src_w:1920, src_h:1080; dst_w:672, dst_h:672;\nSetting VPS channel-3: src_w:1920, src_h:1080; dst_w:1024, dst_h:600;\nSetting VPS channel-2: src_w:1920, src_h:1080; dst_w:1920, dst_h:1080;\nstart linear mode, sensor_name f37, setting_size = 3\nlibiar: hb_disp_set_timing done!\nyolov5_do_post fps:11.627907,processing time :86\n```\n"}}],"contentBlocks":[{"type":"text","content":"我会先备份这个文件,然后优化它。让我先读取文件内容来了解需要做什么优化。"},{"type":"tool_use","toolId":"call_c0e2b318fe8e4f65b374b086"},{"type":"text","content":"现在我将备份这个文件并进行优化。让我先备份,然后进行优化。"},{"type":"tool_use","toolId":"call_9331ef47ec0046a69c886813"},{"type":"text","content":"备份完成。现在我将优化这个文档,主要改进包括:\n\n1. 移除外部网站的链接锚点文本\n2. 优化标题层级和格式\n3. 添加代码块标记\n4. 改进可读性和结构\n5. 添加适当的空行和格式"},{"type":"tool_use","toolId":"call_f66e1b1946c14ea5811c9300"},{"type":"text","content":"完成!我已经完成了文件的备份和优化。主要改进包括:\n\n## 优化内容\n\n1. **移除了冗余的链接锚点文本** - 原文件中每个标题后面都有 `[](... \"永久链接至标题\")` 这样的文本,已全部清理\n\n2. **改进了标题结构** - 使用更清晰的二级标题(###)来组织每个小节的环境准备、运行方式等内容\n\n3. **添加了代码块标记** - 所有命令行和日志输出都用 ```bash ... ``` 包裹,提升了可读性和语法高亮\n\n4. **使用表格组织参数说明** - 将原本的列表形式改为更易读的表格形式\n\n5. **优化了空行和格式** - 增加了适当的空行分隔不同内容区块\n\n6. **修正了路径错误** - 修复了第265行的路径错误(原本写的是 decode2display 目录)\n\n7. **修复了参数说明错误** - 第281行的 `-width` 改为正确的 `-owidth`\n\n备份文件已保存在: [[5.1. 参考示例.backup.md]]"}]}}